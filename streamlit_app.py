# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import urllib.parse
import gspread
from oauth2client.service_account import ServiceAccountCredentials  # v·∫´n gi·ªØ ƒë·ªÉ t∆∞∆°ng th√≠ch n·∫øu c·∫ßn fallback
import qrcode
import re
from PIL import Image
from io import BytesIO
import difflib
import zipfile
import io
import time, random
# --- helper l·∫•y bi·∫øn secret b·∫•t ch·∫•p vi·∫øt hoa/th∆∞·ªùng/th·ª´a kho·∫£ng tr·∫Øng ---
def _get_secret(*names: str) -> str:
    # Chu·∫©n h√≥a key: b·ªè kho·∫£ng tr·∫Øng, h·∫° th∆∞·ªùng, thay '-' th√†nh '_'
    def norm(s): return str(s).strip().lower().replace(" ", "").replace("-", "_")
    # qu√©t st.secrets theo kh√≥a chu·∫©n h√≥a
    wanted = {norm(n) for n in names}
    for k, v in st.secrets.items():
        if norm(k) in wanted:
            return str(v)
    return ""

# ==========================
# C·∫§U H√åNH CHUNG & H·ªñ TR·ª¢
# ==========================
st.set_page_config(page_title="QR Car Management", page_icon="üöó", layout="wide")

REQUIRED_COLUMNS = ["STT", "H·ªç t√™n", "Bi·ªÉn s·ªë", "M√£ th·∫ª", "M√£ ƒë∆°n v·ªã", "T√™n ƒë∆°n v·ªã", "Ch·ª©c v·ª•", "S·ªë ƒëi·ªán tho·∫°i", "Email"]
DON_VI_MAP = {
    "HCTH": "HCT", "TCCB": "TCC", "ƒêTƒêH": "DTD", "ƒêTSƒêH": "DTS", "KHCN": "KHC", "KHTC": "KHT",
    "QTGT": "QTG", "TTPC": "TTP", "ƒêBCLGD&KT": "DBK", "CTSV": "CTS", "Tr∆∞·ªùng Y": "TRY",
    "Tr∆∞·ªùng D∆∞·ª£c": "TRD", "Tr∆∞·ªùng ƒêD-KTYH": "TRK", "KHCB": "KHB", "RHM": "RHM", "YTCC": "YTC",
    "PK.CKRHM": "CKR", "TT.KCCLXN": "KCL", "TT.PTTN": "PTN", "TT.ƒêTNLYT": "DTL", "TT.CNTT": "CNT",
    "TT.KHCN UMP": "KCU", "TT.YSHPT": "YSH", "Th∆∞ vi·ªán": "TV", "KTX": "KTX", "T·∫°p ch√≠ Y h·ªçc": "TCY",
    "BV ƒêHYD": "BVY", "TT. GDYH": "GDY", "VPƒê": "VPD", "YHCT": "YHC", "HTQT": "HTQ"
}

# Sheet/Worksheet d√πng c·ªë ƒë·ªãnh
SHEET_ID = "1a_pMNiQbD5yO58abm4EfNMz7AbQTBmG8QV3yEN500uc"
WORKSHEET_NAME = "Sheet1"  # ƒë√∫ng t√™n sheet trong gg sheet

# ----- Helpers b·∫£ng -----
def clean_df(df: pd.DataFrame) -> pd.DataFrame:
    """ƒê·ªïi t√™n c·ªôt v·ªÅ str, b·ªè c·ªôt Unnamed, reset index."""
    if df is None or df.empty:
        return pd.DataFrame(columns=REQUIRED_COLUMNS)
    cols = [(str(c).strip() if c is not None else "") for c in df.columns]
    df = df.copy()
    df.columns = cols
    keep = [c for c in df.columns if not re.match(r"^\s*Unnamed", c)]
    df = df.loc[:, keep]
    return df.reset_index(drop=True)

def normalize_plate(plate: str) -> str:
    return re.sub(r'[^a-zA-Z0-9]', '', str(plate)).lower()

def format_name(name: str) -> str:
    return ' '.join(word.capitalize() for word in str(name).strip().split())

def dinh_dang_bien_so(bs: str) -> str:
    bs = re.sub(r"[^A-Z0-9]", "", str(bs).upper())
    if len(bs) == 8:
        return f"{bs[:3]}-{bs[3:6]}.{bs[6:]}"
    return bs

def _df_to_values(df, columns):
    vals = []
    for _, r in df.iterrows():
        row = []
        for c in columns:
            v = r.get(c, "")
            if pd.isna(v): v = ""
            row.append(str(v))
        vals.append(row)
    return vals

def gs_retry(func, *args, max_retries=7, base=0.6, **kwargs):
    """Retry nh·∫π nh√†ng khi d√≠nh quota/timeout 429/5xx."""
    for i in range(max_retries):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            msg = str(e).lower()
            if any(t in msg for t in ["quota", "rate limit", "timeout", "internal error", "503", "500", "429"]):
                time.sleep(base * (2 ** i) + random.uniform(0, 0.5))
                continue
            raise
    raise RuntimeError(f"Google Sheets API failed sau {max_retries} l·∫ßn th·ª≠")

def write_bulk_block(ws, df_cur: pd.DataFrame, df_new: pd.DataFrame,
                     columns=None, chunk_rows=500, pause=0.5):
    """Append c·∫£ DataFrame theo block ƒë·ªÉ tr√°nh quota."""
    if columns is None:
        columns = REQUIRED_COLUMNS
    df_new = df_new.copy()
    values = _df_to_values(df_new, columns)
    if not values:
        return 0
    start = len(df_cur) + 2  # + header
    written = 0
    for i in range(0, len(values), chunk_rows):
        block = values[i:i+chunk_rows]
        end_row = start + i + len(block) - 1
        rng = f"A{start+i}:I{end_row}"
        gs_retry(ws.update, rng, block)
        written += len(block)
        if pause: time.sleep(pause)
    return written

def ensure_columns(df: pd.DataFrame):
    missing = [c for c in REQUIRED_COLUMNS if c not in df.columns]
    if missing:
        raise ValueError(f"Thi·∫øu c·ªôt b·∫Øt bu·ªôc: {', '.join(missing)}")
    return df[REQUIRED_COLUMNS].copy()

def resolve_ma_don_vi(ten_dv: str, ma_dv_cur: str = "") -> str:
    """Lu√¥n tr·∫£ m√£ ƒë∆°n v·ªã n·∫øu t√™n ƒë∆°n v·ªã h·ª£p l·ªá; n·∫øu ch∆∞a c√≥ trong map th√¨ t·∫°o t·∫°m 3 k√Ω t·ª± ƒë·∫ßu."""
    if str(ma_dv_cur).strip():
        return str(ma_dv_cur).strip().upper()
    name = str(ten_dv).strip()
    if not name:
        return ""
    ma = DON_VI_MAP.get(name)
    if ma:
        return ma.upper()
    # fallback: l·∫•y 3 ch·ªØ c√°i ƒë·∫ßu (vi·∫øt hoa, b·ªè d·∫•u)
    name_ascii = re.sub(r"[^A-Z]", "", re.sub(r"ƒê", "D", name.upper()))
    return name_ascii[:3] if name_ascii else ""


def build_unit_counters(df_cur: pd.DataFrame) -> dict:
    counters = {}
    if "M√£ th·∫ª" in df_cur.columns:
        for val in df_cur["M√£ th·∫ª"].dropna().astype(str):
            m = re.match(r"^([A-Z]{3})(\d{3})$", val.strip().upper())
            if m:
                unit, num = m.group(1), int(m.group(2))
                counters[unit] = max(counters.get(unit, 0), num)
    return counters

def assign_codes_for_row(row: pd.Series, counters: dict) -> pd.Series:
    ma_dv = resolve_ma_don_vi(row.get("T√™n ƒë∆°n v·ªã", ""), row.get("M√£ ƒë∆°n v·ªã", ""))
    row["M√£ ƒë∆°n v·ªã"] = ma_dv
    ma_the = str(row.get("M√£ th·∫ª", "") or "").strip().upper()
    if not ma_dv:
        return row
    if not ma_the:
        cur = counters.get(ma_dv, 0) + 1
        counters[ma_dv] = cur
        row["M√£ th·∫ª"] = f"{ma_dv}{cur:03d}"
    else:
        m = re.match(rf"^{ma_dv}(\d{{3}})$", ma_the)
        if m:
            counters[ma_dv] = max(counters.get(ma_dv, 0), int(m.group(1)))
        row["M√£ th·∫ª"] = ma_the
    return row
def fill_missing_codes_strict(df_new: pd.DataFrame, df_cur: pd.DataFrame) -> pd.DataFrame:
    """
    - T·ª± g√°n 'M√£ ƒë∆°n v·ªã' t·ª´ 'T√™n ƒë∆°n v·ªã' (theo DON_VI_MAP). N·∫øu kh√¥ng map ƒë∆∞·ª£c ‚Üí ƒë·ªÉ r·ªóng.
    - T·ª± sinh 'M√£ th·∫ª' theo t·ª´ng 'M√£ ƒë∆°n v·ªã' (gi·ªØ l·∫°i m√£ ƒë√£ c√≥ ƒë√∫ng format).
    - Seed s·ªë ch·∫°y d·ª±a tr√™n df_cur hi·ªán c√≥.
    """
    df = df_new.copy()

    # B·∫£o ƒë·∫£m ƒë·ªß c·ªôt & lo·∫°i NaN th√†nh r·ªóng
    for c in REQUIRED_COLUMNS:
        if c not in df.columns:
            df[c] = ""
    df = df.fillna("")

    # 1) M√£ ƒë∆°n v·ªã
    def _resolve_unit(row):
        ma_cur = str(row.get("M√£ ƒë∆°n v·ªã", "")).strip().upper()
        if ma_cur:
            return ma_cur
        name = str(row.get("T√™n ƒë∆°n v·ªã", "")).strip()
        if not name:
            return ""
        return DON_VI_MAP.get(name, "").upper()

    df["M√£ ƒë∆°n v·ªã"] = df.apply(_resolve_unit, axis=1)

    # 2) M√£ th·∫ª theo t·ª´ng ƒë∆°n v·ªã (seed t·ª´ d·ªØ li·ªáu ƒëang c√≥)
    counters = build_unit_counters(df_cur)

    def _gen_codes(group: pd.DataFrame) -> pd.Series:
        unit = str(group.name or "").strip().upper()
        if not unit:
            # kh√¥ng c√≥ ƒë∆°n v·ªã ‚Üí tr·∫£ nguy√™n gi√° tr·ªã (nh∆∞ng ƒë·ªïi NaN -> r·ªóng)
            return group["M√£ th·∫ª"].astype(str).replace({"nan": ""})
        cur = counters.get(unit, 0)
        out = []
        for v in group["M√£ th·∫ª"].astype(str):
            v2 = (v or "").strip().upper()
            if v2 in ("", "NAN"):
                cur += 1
                out.append(f"{unit}{cur:03d}")
            else:
                m = re.match(rf"^{unit}(\d{{3}})$", v2)
                if m:
                    cur = max(cur, int(m.group(1)))
                out.append(v2)
        counters[unit] = cur
        return pd.Series(out, index=group.index)

    df["M√£ th·∫ª"] = df.groupby("M√£ ƒë∆°n v·ªã", dropna=False, group_keys=False).apply(_gen_codes)

    # 3) Chu·∫©n ho√° STT (n·∫øu mu·ªën)
    try:
        df["STT"] = pd.RangeIndex(1, len(df) + 1)
    except Exception:
        pass

    return df[REQUIRED_COLUMNS].copy()

def reindex_stt(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df["STT"] = list(range(1, len(df) + 1))
    return df

def make_qr_bytes(url: str) -> bytes:
    img = qrcode.make(url)
    buf = BytesIO()
    img.save(buf)
    buf.seek(0)
    return buf.getvalue()

# ==========================
# K·∫æT N·ªêI GOOGLE SHEETS
# ==========================
from google.oauth2.service_account import Credentials

def get_sheet():
    """M·ªü ƒë√∫ng SHEET_ID + tab WORKSHEET_NAME; t·ª± t·∫°o header n·∫øu sheet m·ªõi."""
    info = st.secrets["google_service_account"]
    # N·∫øu private_key b·ªã d√°n d·∫°ng '\n' th√¨ chuy·ªÉn v·ªÅ xu·ªëng d√≤ng th·∫≠t
    info2 = dict(info)
    pk = info2.get("private_key", "")
    if isinstance(pk, str) and "\\n" in pk and "BEGIN PRIVATE KEY" in pk:
        info2["private_key"] = pk.replace("\\n", "\n")

    scopes = ["https://www.googleapis.com/auth/spreadsheets"]
    try:
        creds = Credentials.from_service_account_info(info2, scopes=scopes)
    except Exception:
        creds = ServiceAccountCredentials.from_json_keyfile_dict(info2, scopes=scopes)

    gc = gspread.authorize(creds)
    sh = gc.open_by_key(SHEET_ID)
    try:
        ws = sh.worksheet(WORKSHEET_NAME)  # "Sheet1"
    except gspread.WorksheetNotFound:
        ws = sh.add_worksheet(title=WORKSHEET_NAME, rows="2000", cols="20")
        gs_retry(ws.update, "A1", [REQUIRED_COLUMNS])
    return ws

try:
    ws = get_sheet()
except Exception as e:
    st.error(f"‚ùå L·ªói m·ªü Google Sheet: {e}")
    st.stop()

# ==========================
# B·∫¢O V·ªÜ ‚Äì M·∫¨T KH·∫®U
# ==========================
APP_PASSWORD = st.secrets.get("app_password") or st.secrets.get("qr_password")
if not APP_PASSWORD:
    st.error("‚ùå Thi·∫øu m·∫≠t kh·∫©u ·ª©ng d·ª•ng trong secrets (app_password ho·∫∑c qr_password).")
    st.stop()

# ==========================
# LOAD D·ªÆ LI·ªÜU CH√çNH
# ==========================
@st.cache_data(ttl=60)
def load_df():
    try:
        data = ws.get_all_records()
        return pd.DataFrame(data)
    except Exception as e:
        st.error(f"‚ùå Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu xe: {e}")
        st.stop()

# ====== QR gate: m·∫≠t kh·∫©u QR ri√™ng & ch·ªâ hi·ªÉn th·ªã ƒë√∫ng 1 xe r·ªìi d·ª´ng ======
QR_PASSWORD = _get_secret("QR_PASSWORD", "qr_password", "qrpassword", "qr_pwd")  # CH·ªà m·∫≠t kh·∫©u QR

# L·∫•y id=? t∆∞∆°ng th√≠ch API m·ªõi/c≈©
try:
    qp = getattr(st, "query_params", None)
    params = dict(qp) if qp is not None else st.experimental_get_query_params()
except Exception:
    params = st.experimental_get_query_params()

qr_id = ""
if "id" in params:
    v = params["id"]
    qr_id = v[0] if isinstance(v, list) else str(v)

if qr_id:
    # ·∫®n sidebar khi m·ªü b·∫±ng QR
    st.markdown("""
        <style>
        [data-testid="stSidebar"], [data-testid="stSidebarNav"], [data-testid="stSidebarContent"]{display:none!important;}
        </style>
    """, unsafe_allow_html=True)

    st.subheader("üîç Tra c·ª©u xe qua QR")

    if not QR_PASSWORD:
        st.error("Thi·∫øu QR_PASSWORD trong secrets."); st.stop()

    pwd = st.text_input("üîë Nh·∫≠p m·∫≠t kh·∫©u QR", type="password", placeholder="M·∫≠t kh·∫©u ch·ªâ ƒë·ªÉ xem QR")
    if not pwd:
        st.info("Vui l√≤ng nh·∫≠p m·∫≠t kh·∫©u QR ƒë·ªÉ xem th√¥ng tin xe."); st.stop()
    if pwd.strip() != QR_PASSWORD:
        st.error("‚ùå Sai m·∫≠t kh·∫©u QR."); st.stop()

    # ƒê√∫ng m·∫≠t kh·∫©u QR ‚Üí ch·ªâ hi·ªÉn th·ªã b·∫£n ghi kh·ªõp r·ªìi D·ª™NG
    df0 = load_df().copy()
    df0["__plate_norm"] = df0["Bi·ªÉn s·ªë"].astype(str).apply(normalize_plate)
    df0["__card_up"]    = df0.get("M√£ th·∫ª", "").astype(str).str.upper().str.strip()

    q_up = str(qr_id).upper().strip()
    q_norm = normalize_plate(str(qr_id))

    # ∆Øu ti√™n kh·ªõp M√É TH·∫∫; n·∫øu kh√¥ng c√≥ th√¨ kh·ªõp bi·ªÉn s·ªë chu·∫©n h√≥a
    if re.fullmatch(r"[A-Z]{3}\d{3}", q_up):
        view = df0[df0["__card_up"].eq(q_up)]
    else:
        view = df0[df0["__plate_norm"].eq(q_norm)]

    if view.empty:
        st.error(f"Kh√¥ng t√¨m th·∫•y xe v·ªõi m√£/bi·ªÉn s·ªë: {qr_id}")
    else:
        st.success("‚úÖ Th√¥ng tin xe:")
        st.dataframe(
            view.drop(columns=["__plate_norm","__card_up"], errors="ignore"),
            hide_index=True, use_container_width=True
        )
    st.stop()  # B·∫ÆT BU·ªòC: kh√¥ng cho ch·∫°y xu·ªëng app qu·∫£n tr·ªã

# C·ªïng ƒëƒÉng nh·∫≠p app
if "auth_ok" not in st.session_state:
    st.session_state.auth_ok = False
st.markdown("<h1 style='text-align:center; color:#004080;'>üöó QR Car Management</h1>", unsafe_allow_html=True)
if not st.session_state.auth_ok:
    st.markdown("### üîê ƒêƒÉng nh·∫≠p")
    pwd = st.text_input("M·∫≠t kh·∫©u", type="password")
    if st.button("ƒêƒÉng nh·∫≠p"):
        if pwd.strip() == str(APP_PASSWORD):
            st.session_state.auth_ok = True
            st.success("‚úÖ ƒêƒÉng nh·∫≠p th√†nh c√¥ng.")
        else:
            st.error("‚ùå Sai m·∫≠t kh·∫©u!")
    st.stop()

# Sau ƒëƒÉng nh·∫≠p
st.sidebar.image("ump_logo.png", width=120)
st.sidebar.markdown("---")

if "df" not in st.session_state:
    st.session_state.df = load_df()
df = st.session_state.df

# ==========================
# MENU
# ==========================
menu = [
    "üìã Xem danh s√°ch",
    "üîç T√¨m ki·∫øm xe",
    "‚ûï ƒêƒÉng k√Ω xe m·ªõi",
    "‚úèÔ∏è C·∫≠p nh·∫≠t xe",
    "üóëÔ∏è X√≥a xe",
    "üì• T·∫£i d·ªØ li·ªáu l√™n",
    "üéÅ T·∫°o m√£ QR h√†ng lo·∫°t",
    "üì§ Xu·∫•t ra Excel",
    "üìä Th·ªëng k√™",
    "ü§ñ Tr·ª£ l√Ω AI"
]
choice = st.sidebar.radio("üìå Ch·ªçn ch·ª©c nƒÉng", menu, index=0)

# ==========================
# CH·ª®C NƒÇNG
# ==========================
if choice == "üìã Xem danh s√°ch":
    st.subheader("üìã Danh s√°ch xe ƒë√£ ƒëƒÉng k√Ω")
    df_show = clean_df(df.copy())
    if "Bi·ªÉn s·ªë" in df_show.columns:
        df_show["Bi·ªÉn s·ªë"] = df_show["Bi·ªÉn s·ªë"].apply(dinh_dang_bien_so)
    st.dataframe(df_show, hide_index=True, use_container_width=True)

elif choice == "üîç T√¨m ki·∫øm xe":
    st.subheader("üîç T√¨m ki·∫øm xe theo bi·ªÉn s·ªë (h·ªó tr·ª£ g·∫ßn ƒë√∫ng)")
    bien_so_input = st.text_input("Nh·∫≠p bi·ªÉn s·ªë xe c·∫ßn t√¨m")
    allow_fuzzy = st.checkbox("Cho ph√©p g·ª£i √Ω g·∫ßn ƒë√∫ng n·∫øu kh√¥ng kh·ªõp tuy·ªát ƒë·ªëi", value=True)
    if bien_so_input:
        bien_so_norm = normalize_plate(bien_so_input)
        df_tmp = df.copy()
        df_tmp["Bi·ªÉn s·ªë chu·∫©n h√≥a"] = df_tmp["Bi·ªÉn s·ªë"].astype(str).apply(normalize_plate)
        ket_qua = df_tmp[df_tmp["Bi·ªÉn s·ªë chu·∫©n h√≥a"] == bien_so_norm]
        if ket_qua.empty and allow_fuzzy:
            st.info("Kh√¥ng kh·ªõp tuy·ªát ƒë·ªëi. Th·ª≠ g·ª£i √Ω g·∫ßn ƒë√∫ng‚Ä¶")
            # g·ª£i √Ω g·∫ßn ƒë√∫ng ƒë∆°n gi·∫£n
            def fuzzy_ratio(a: str, b: str) -> float:
                return difflib.SequenceMatcher(None, str(a).lower(), str(b).lower()).ratio()
            scores = []
            for idx, row in df.iterrows():
                s = 0.0
                s += 2.0 * fuzzy_ratio(bien_so_input, row.get("Bi·ªÉn s·ªë", ""))
                s += fuzzy_ratio(bien_so_input, row.get("H·ªç t√™n", ""))
                s += fuzzy_ratio(bien_so_input, row.get("M√£ th·∫ª", ""))
                s += 0.8 * fuzzy_ratio(bien_so_input, row.get("T√™n ƒë∆°n v·ªã", ""))
                scores.append((idx, s))
            scores.sort(key=lambda x: x[1], reverse=True)
            idxs = [i for i, _ in scores[:20]]
            top = df.loc[idxs].copy()
            st.success(f"‚úÖ G·ª£i √Ω g·∫ßn ƒë√∫ng (top {len(top)}):")
            st.dataframe(top, hide_index=True, use_container_width=True)
        elif ket_qua.empty:
            st.warning("üö´ Kh√¥ng t√¨m th·∫•y xe n√†o kh·ªõp v·ªõi bi·ªÉn s·ªë ƒë√£ nh·∫≠p.")
        else:
            st.success(f"‚úÖ T√¨m th·∫•y {len(ket_qua)} xe kh·ªõp.")
            st.dataframe(ket_qua.drop(columns=["Bi·ªÉn s·ªë chu·∫©n h√≥a"]), hide_index=True, use_container_width=True)

elif choice == "‚ûï ƒêƒÉng k√Ω xe m·ªõi":
    st.subheader("üìã ƒêƒÉng k√Ω xe m·ªõi")
    df_current = df.copy()
    ten_don_vi = st.selectbox("Ch·ªçn ƒë∆°n v·ªã", list(DON_VI_MAP.keys()))
    ma_don_vi = DON_VI_MAP[ten_don_vi]
    col1, col2 = st.columns(2)
    with col1:
        ho_ten_raw = st.text_input("H·ªç t√™n")
        bien_so_raw = st.text_input("Bi·ªÉn s·ªë xe")
    with col2:
        chuc_vu_raw = st.text_input("Ch·ª©c v·ª•")
        so_dien_thoai = st.text_input("S·ªë ƒëi·ªán tho·∫°i")
        email = st.text_input("Email")
    ho_ten = format_name(ho_ten_raw)
    chuc_vu = format_name(chuc_vu_raw)
    bien_so = dinh_dang_bien_so(bien_so_raw)
    bien_so_da_dang_ky = df_current["Bi·ªÉn s·ªë"].dropna().apply(dinh_dang_bien_so)

    if st.button("üì• ƒêƒÉng k√Ω"):
        if bien_so in bien_so_da_dang_ky.values:
            st.error("üö´ Bi·ªÉn s·ªë n√†y ƒë√£ ƒë∆∞·ª£c ƒëƒÉng k√Ω tr∆∞·ªõc ƒë√≥!")
        elif so_dien_thoai and not str(so_dien_thoai).startswith("0"):
            st.warning("‚ö†Ô∏è S·ªë ƒëi·ªán tho·∫°i ph·∫£i b·∫Øt ƒë·∫ßu b·∫±ng s·ªë 0.")
        elif ho_ten == "" or bien_so == "":
            st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p ƒë·∫ßy ƒë·ªß th√¥ng tin.")
        else:
            try:
                counters = build_unit_counters(df_current)
                cur = counters.get(ma_don_vi, 0) + 1
                ma_the = f"{ma_don_vi}{cur:03d}"
                gs_retry(ws.append_row, [
                    int(len(df_current) + 1),
                    ho_ten, bien_so, ma_the, ma_don_vi, ten_don_vi,
                    chuc_vu, so_dien_thoai, email
                ])
                st.success(f"‚úÖ ƒê√£ ƒëƒÉng k√Ω xe cho `{ho_ten}` v·ªõi m√£ th·∫ª: `{ma_the}`")
                norm = normalize_plate(bien_so)
                link = f"https://qrcarump.streamlit.app/?id={urllib.parse.quote(norm)}"
                qr_png = make_qr_bytes(link)
                st.image(qr_png, caption=f"QR cho {bien_so}", width=200)
                st.download_button("üì• T·∫£i m√£ QR", data=qr_png, file_name=f"QR_{bien_so}.png", mime="image/png")
                st.caption("Qu√©t m√£ s·∫Ω y√™u c·∫ßu m·∫≠t kh·∫©u tr∆∞·ªõc khi xem th√¥ng tin.")
                st.session_state.df = load_df()
            except Exception as e:
                st.error(f"‚ùå L·ªói ghi d·ªØ li·ªáu: {e}")

elif choice == "‚úèÔ∏è C·∫≠p nh·∫≠t xe":
    st.subheader("‚úèÔ∏è C·∫≠p nh·∫≠t xe")
    bien_so_input = st.text_input("Nh·∫≠p bi·ªÉn s·ªë xe c·∫ßn c·∫≠p nh·∫≠t")
    if bien_so_input:
        bien_so_norm = normalize_plate(bien_so_input)
        df_tmp = df.copy()
        df_tmp["Bi·ªÉn s·ªë chu·∫©n h√≥a"] = df_tmp["Bi·ªÉn s·ªë"].astype(str).apply(normalize_plate)
        ket_qua = df_tmp[df_tmp["Bi·ªÉn s·ªë chu·∫©n h√≥a"] == bien_so_norm]
        if ket_qua.empty:
            st.error("‚ùå Kh√¥ng t√¨m th·∫•y bi·ªÉn s·ªë xe!")
        else:
            st.success(f"‚úÖ T√¨m th·∫•y {len(ket_qua)} xe kh·ªõp.")
            st.dataframe(ket_qua.drop(columns=["Bi·ªÉn s·ªë chu·∫©n h√≥a"]), hide_index=True, use_container_width=True)
            idx_np = ket_qua.index[0]
            index = int(idx_np)
            row = ket_qua.iloc[0]
            st.markdown("### üìù Nh·∫≠p th√¥ng tin m·ªõi ƒë·ªÉ c·∫≠p nh·∫≠t")
            col1, col2 = st.columns(2)
            with col1:
                ho_ten_moi = st.text_input("H·ªç t√™n", value=str(row["H·ªç t√™n"]))
                bien_so_moi = st.text_input("Bi·ªÉn s·ªë xe", value=str(row["Bi·ªÉn s·ªë"]))
                ten_don_vi_moi = st.text_input("T√™n ƒë∆°n v·ªã", value=str(row["T√™n ƒë∆°n v·ªã"]))
                ma_don_vi_moi = st.text_input("M√£ ƒë∆°n v·ªã", value=str(row["M√£ ƒë∆°n v·ªã"]))
            with col2:
                chuc_vu_moi = st.text_input("Ch·ª©c v·ª•", value=str(row["Ch·ª©c v·ª•"]))
                so_dien_thoai_moi = st.text_input("S·ªë ƒëi·ªán tho·∫°i", value=str(row["S·ªë ƒëi·ªán tho·∫°i"]))
                email_moi = st.text_input("Email", value=str(row["Email"]))
            if st.button("C·∫≠p nh·∫≠t"):
                try:
                    try:
                        stt_val = int(row.get("STT", ""))
                    except Exception:
                        stt_val = str(row.get("STT", ""))
                    payload = [
                        stt_val, ho_ten_moi, bien_so_moi, str(row["M√£ th·∫ª"]),
                        ma_don_vi_moi, ten_don_vi_moi, chuc_vu_moi, so_dien_thoai_moi, email_moi
                    ]
                    gs_retry(ws.update, f"A{index+2}:I{index+2}", [payload])
                    st.success("‚úÖ ƒê√£ c·∫≠p nh·∫≠t th√¥ng tin xe th√†nh c√¥ng!")
                    norm = normalize_plate(bien_so_moi)
                    link = f"https://qrcarump.streamlit.app/?id={urllib.parse.quote(norm)}"
                    qr_png = make_qr_bytes(link)
                    st.image(qr_png, caption=f"QR cho {bien_so_moi}", width=200)
                    st.download_button("üì• T·∫£i m√£ QR", data=qr_png, file_name=f"QR_{bien_so_moi}.png", mime="image/png")
                    st.caption("Qu√©t m√£ s·∫Ω y√™u c·∫ßu m·∫≠t kh·∫©u tr∆∞·ªõc khi xem th√¥ng tin.")
                    st.session_state.df = load_df()
                except Exception as e:
                    st.error(f"‚ùå L·ªói c·∫≠p nh·∫≠t: {e}")

elif choice == "üóëÔ∏è X√≥a xe":
    st.subheader("üóëÔ∏è X√≥a xe kh·ªèi danh s√°ch")
    bien_so_input = st.text_input("Nh·∫≠p bi·ªÉn s·ªë xe c·∫ßn x√≥a")
    if bien_so_input:
        try:
            bien_so_norm = normalize_plate(bien_so_input)
            df_tmp = df.copy()
            df_tmp["Bi·ªÉn s·ªë chu·∫©n h√≥a"] = df_tmp["Bi·ªÉn s·ªë"].astype(str).apply(normalize_plate)
            ket_qua = df_tmp[df_tmp["Bi·ªÉn s·ªë chu·∫©n h√≥a"] == bien_so_norm]
            if ket_qua.empty:
                st.error("‚ùå Kh√¥ng t√¨m th·∫•y bi·ªÉn s·ªë xe!")
            else:
                st.success(f"‚úÖ T√¨m th·∫•y {len(ket_qua)} xe kh·ªõp.")
                st.dataframe(ket_qua.drop(columns=["Bi·ªÉn s·ªë chu·∫©n h√≥a"]), hide_index=True, use_container_width=True)
                idx_np = ket_qua.index[0]
                index = int(idx_np)
                row = ket_qua.iloc[0]
                if st.button("X√°c nh·∫≠n x√≥a"):
                    gs_retry(ws.delete_rows, int(index) + 2)
                    st.success(f"üóëÔ∏è ƒê√£ x√≥a xe c√≥ bi·ªÉn s·ªë `{row['Bi·ªÉn s·ªë']}` th√†nh c√¥ng!")
                    st.session_state.df = load_df()
        except Exception as e:
            st.error(f"‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω: {e}")

elif choice == "üì• T·∫£i d·ªØ li·ªáu l√™n":
    st.subheader("üì• T·∫£i d·ªØ li·ªáu t·ª´ Excel/CSV")
    up = st.file_uploader("Ch·ªçn t·ªáp Excel (.xlsx) ho·∫∑c CSV", type=["xlsx", "csv"])
    mode = st.selectbox("Ch·∫ø ƒë·ªô ghi d·ªØ li·ªáu", ["Th√™m (append)", "Thay th·∫ø to√†n b·ªô (replace all)", "Upsert"])
    dry_run = st.checkbox("üîé Ch·∫°y th·ª≠ (kh√¥ng ghi Google Sheets)")

    if up is not None:
        try:
            if up.name.lower().endswith(".csv"):
                df_up = pd.read_csv(up, dtype=str, keep_default_na=False)
            else:
                df_up = pd.read_excel(up, dtype=str)
        except Exception as e:
            st.error(f"‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c t·ªáp: {e}")
            st.stop()

        df_up = clean_df(df_up)
        for c in REQUIRED_COLUMNS:
            if c not in df_up.columns:
                df_up[c] = ""

        

        st.info(f"ƒê√£ n·∫°p {len(df_up)} d√≤ng.")

        if st.button("üöÄ Th·ª±c thi"):
            try:
                cur_vals = gs_retry(ws.get_all_values)
                if not cur_vals:
                    gs_retry(ws.update, "A1", [REQUIRED_COLUMNS])
                    df_cur = pd.DataFrame(columns=REQUIRED_COLUMNS)
                else:
                    header, rows = cur_vals[0], cur_vals[1:]
                    rows = [r + [""]*(len(header)-len(r)) if len(r) < len(header) else r[:len(header)] for r in rows]
                    df_cur = pd.DataFrame(rows, columns=header)
                    for c in REQUIRED_COLUMNS:
                        if c not in df_cur.columns:
                            df_cur[c] = ""

                df_to_write = fill_missing_codes_strict(df_up, df_cur)

                if dry_run:
                    st.info("üîé Ch·∫°y th·ª≠: kh√¥ng ghi Google Sheets.")
                else:
                    if mode == "Th√™m (append)":
                        added = write_bulk_block(ws, df_cur, df_to_write, columns=REQUIRED_COLUMNS)
                        st.success(f"‚úÖ ƒê√£ th√™m {added} d√≤ng.")
                    elif mode == "Thay th·∫ø to√†n b·ªô (replace all)":
                        gs_retry(ws.clear)
                        gs_retry(ws.update, "A1", [REQUIRED_COLUMNS])
                        vals = _df_to_values(df_to_write, REQUIRED_COLUMNS)
                        if vals:
                            gs_retry(ws.update, f"A2:I{1+len(vals)}", vals)
                        st.success(f"‚úÖ ƒê√£ thay th·∫ø to√†n b·ªô d·ªØ li·ªáu ({len(df_to_write)} d√≤ng).")
                    else:
                        # Upsert nhanh
                        df_cur2 = df_cur.copy()
                        def _keyify(d):
                            k1 = d.get("M√£ th·∫ª", pd.Series([""]*len(d))).astype(str).str.upper().str.strip()
                            k2 = d["Bi·ªÉn s·ªë"].astype(str).map(normalize_plate) if "Bi·ªÉn s·ªë" in d.columns else pd.Series([""]*len(d))
                            return k1.where(k1 != "", k2)

                        df_cur2["__KEY__"] = _keyify(df_cur2)
                        df_to_write["__KEY__"] = _keyify(df_to_write)
                        key_to_row = {k: i for i, k in df_cur2["__KEY__"].items() if str(k).strip() != ""}

                        updates, inserts = [], []
                        for _, r in df_to_write.iterrows():
                            key = str(r["__KEY__"]).strip()
                            payload = [str(r.get(c, "")) for c in REQUIRED_COLUMNS]
                            if key and key in key_to_row:
                                idx0 = int(key_to_row[key])
                                updates.append((idx0+2, payload))
                            else:
                                inserts.append(payload)

                        updates.sort(key=lambda x: x[0])
                        grp, prev = [], None
                        for rownum, payload in updates:
                            if prev is None or rownum == prev + 1:
                                grp.append((rownum, payload))
                            else:
                                rng = f"A{grp[0][0]}:I{grp[-1][0]}"
                                gs_retry(ws.update, rng, [p for _, p in grp])
                                grp = [(rownum, payload)]
                            prev = rownum
                        if grp:
                            rng = f"A{grp[0][0]}:I{grp[-1][0]}"
                            gs_retry(ws.update, rng, [p for _, p in grp])

                        if inserts:
                            start = len(df_cur2) + 2
                            for i in range(0, len(inserts), 500):
                                blk = inserts[i:i+500]
                                end_row = start + i + len(blk) - 1
                                rng = f"A{start+i}:I{end_row}"
                                gs_retry(ws.update, rng, blk)

                        st.success(f"‚úÖ Upsert xong: c·∫≠p nh·∫≠t {len(updates)} ‚Ä¢ th√™m m·ªõi {len(inserts)}.")

                st.dataframe(df_to_write.head(20), hide_index=True, use_container_width=True)
            except Exception as e:
                st.error(f"‚ùå L·ªói x·ª≠ l√Ω/ghi d·ªØ li·ªáu: {e}")

elif choice == "üéÅ T·∫°o m√£ QR h√†ng lo·∫°t":
    st.subheader("üéÅ T·∫°o m√£ QR h√†ng lo·∫°t")
    BASE_URL_QR = "https://dhnamgh.github.io/car/index.html"  # GH Pages c·ªßa b·∫°n
    src_opt = st.radio("Ch·ªçn ngu·ªìn d·ªØ li·ªáu", ["To√†n b·ªô danh s√°ch", "Danh s√°ch ƒëang l·ªçc"], horizontal=True)
    if src_opt == "Danh s√°ch ƒëang l·ªçc" and 'df_show' in locals():
        df_qr = df_show.copy()
    else:
        df_qr = df.copy()
    df_qr = clean_df(df_qr)
    for col in ["M√£ th·∫ª", "Bi·ªÉn s·ªë", "M√£ ƒë∆°n v·ªã"]:
        if col not in df_qr.columns:
            df_qr[col] = ""
    st.info(f"M·ªói QR s·∫Ω m·ªü: {BASE_URL_QR}?id=<M√£Th·∫ª>")
    if st.button("‚ö° T·∫°o ZIP m√£ QR"):
        files = []
        for _, r in df_qr.iterrows():
            vid = str(r.get("M√£ th·∫ª", "")).strip()
            if not vid and "Bi·ªÉn s·ªë" in df_qr.columns:
                vid = normalize_plate(r.get("Bi·ªÉn s·ªë", ""))
            if not vid:
                continue
            url = f"{BASE_URL_QR}?id={urllib.parse.quote(vid)}"
            png = make_qr_bytes(url)
            unit = str(r.get("M√£ ƒë∆°n v·ªã", "")).strip().upper() or "NO_UNIT"
            files.append((f"{unit}/{vid}.png", png))
        if not files:
            st.warning("Kh√¥ng c√≥ b·∫£n ghi h·ª£p l·ªá ƒë·ªÉ t·∫°o QR.")
        else:
            bio = io.BytesIO()
            with zipfile.ZipFile(bio, "w", zipfile.ZIP_STORED) as zf:
                for name, data in files:
                    zf.writestr(name, data)
            bio.seek(0)
            st.download_button("‚¨áÔ∏è T·∫£i ZIP QR (ph√¢n theo ƒë∆°n v·ªã)",
                               data=bio.getvalue(),
                               file_name="qr_xe_theo_don_vi.zip",
                               mime="application/zip")
            st.success(f"‚úÖ ƒê√£ t·∫°o {len(files)} QR.")

elif choice == "üì§ Xu·∫•t ra Excel":
    st.subheader("üì§ T·∫£i danh s√°ch xe d∆∞·ªõi d·∫°ng Excel")
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='DanhSachXe')
    processed_data = output.getvalue()
    st.download_button(label="üì• T·∫£i Excel",
                       data=processed_data,
                       file_name="DanhSachXe.xlsx",
                       mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

elif choice == "üìä Th·ªëng k√™":
    st.markdown("## üìä Dashboard th·ªëng k√™ xe theo ƒë∆°n v·ªã")
    df_stats = df.copy()

    import unicodedata
    def _unit_norm(x: str) -> str:
        s = "" if x is None else str(x)
        s = s.replace("\xa0", " ")
        s = unicodedata.normalize("NFKC", s)
        s = s.replace("√ê", "ƒê").replace("ƒë", "ƒê")
        s = re.sub(r"\s+", " ", s).strip()
        return s

    df_stats["__unit"] = df_stats["T√™n ƒë∆°n v·ªã"].apply(_unit_norm)

    ten_day_du = {
        "HCTH": "Ph√≤ng H√†nh Ch√≠nh T·ªïng h·ª£p",
        "TCCB": "Ph√≤ng T·ªï ch·ª©c C√°n b·ªô",
        "ƒêTƒêH": "Ph√≤ng ƒê√†o t·∫°o ƒê·∫°i h·ªçc",
        "ƒêTSƒêH": "Ph√≤ng ƒê√†o t·∫°o Sau ƒë·∫°i h·ªçc",
        "KHCN": "Ph√≤ng Khoa h·ªçc C√¥ng ngh·ªá",
        "KHTC": "Ph√≤ng K·∫ø ho·∫°ch T√†i ch√≠nh",
        "QTGT": "Ph√≤ng Qu·∫£n tr·ªã Gi√°o t√†i",
        "TTPC": "Ph√≤ng Thanh tra Ph√°p ch·∫ø",
        "ƒêBCLGD&KT": "Ph√≤ng ƒê·∫£m b·∫£o ch·∫•t l∆∞·ª£ng GD v√† Kh·∫£o th√≠",
        "CTSV": "Ph√≤ng C√¥ng t√°c sinh vi√™n",
        "KHCB": "Khoa Khoa h·ªçc C∆° b·∫£n",
        "RHM": "Khoa RƒÉng h√†m m·∫∑t",
        "YTCC": "Khoa Y t·∫ø C√¥ng c·ªông",
        "PK.CKRHM": "Ph√≤ng kh√°m RHM",
        "TT.KCCLXN": "Trung t√¢m Ki·ªÉm chu·∫©n CLXN",
        "TT.KHCN UMP": "Trung t√¢m KHCN UMP",
        "TT.YSHPT": "Trung t√¢m Y sinh h·ªçc ph√¢n t·ª≠",
        "KTX": "K√Ω t√∫c x√°",
        "BV ƒêHYD": "B·ªánh vi·ªán ƒêHYD",
        "TT.PTTN": "Trung t√¢m PTTN",
        "TT. GDYH": "Trung t√¢m GDYH",
        "VPƒê": "VP ƒêo√†n th·ªÉ",
        "Tr∆∞·ªùng Y": "Tr∆∞·ªùng Y",
        "Tr∆∞·ªùng D∆∞·ª£c": "Tr∆∞·ªùng D∆∞·ª£c",
        "Tr∆∞·ªùng ƒêD-KTYH": "Tr∆∞·ªùng ƒêD-KTYH",
        "Th∆∞ vi·ªán": "Th∆∞ vi·ªán",
        "T·∫°p ch√≠ Y h·ªçc": "T·∫°p ch√≠ Y h·ªçc",
        "YHCT": "Khoa Y h·ªçc C·ªï truy·ªÅn",
        "HTQT": "Ph√≤ng H·ª£p t√°c Qu·ªëc t·∫ø"
    }

    thong_ke = (
        df_stats.groupby("__unit", dropna=False)
        .size()
        .reset_index(name="S·ªë l∆∞·ª£ng xe")
        .rename(columns={"__unit": "T√™n ƒë∆°n v·ªã"})
    )
    thong_ke = thong_ke.sort_values(by="S·ªë l∆∞·ª£ng xe", ascending=False)
    thong_ke["T√™n ƒë·∫ßy ƒë·ªß"] = thong_ke["T√™n ƒë∆°n v·ªã"].apply(lambda x: ten_day_du.get(x, x))

    import plotly.express as px
    fig = px.bar(thong_ke, x="T√™n ƒë∆°n v·ªã", y="S·ªë l∆∞·ª£ng xe", color="T√™n ƒë∆°n v·ªã", text="S·ªë l∆∞·ª£ng xe",
                 title="üìà Bi·ªÉu ƒë·ªì s·ªë l∆∞·ª£ng xe theo ƒë∆°n v·ªã")
    fig.update_traces(textposition="outside")
    fig.update_layout(showlegend=False, height=600)
    col = st.columns([0.1, 0.9])
    with col[1]:
        st.plotly_chart(fig, use_container_width=True)
    st.markdown("#### üìã B·∫£ng th·ªëng k√™ chi ti·∫øt")
    thong_ke_display = thong_ke[["T√™n ƒë·∫ßy ƒë·ªß", "S·ªë l∆∞·ª£ng xe"]].rename(columns={"T√™n ƒë·∫ßy ƒë·ªß": "T√™n ƒë∆°n v·ªã"})
    thong_ke_display.index = range(1, len(thong_ke_display) + 1)
    thong_ke_display["S·ªë l∆∞·ª£ng xe"] = thong_ke_display["S·ªë l∆∞·ª£ng xe"].astype(str)
    st.dataframe(thong_ke_display, hide_index=True, use_container_width=True)


elif choice == "ü§ñ Tr·ª£ l√Ω AI":
    st.subheader("ü§ñ Tr·ª£ l√Ω AI (l·ªçc theo T·ª™ tr·ªçn v·∫πn, nhi·ªÅu t·ª´ ‚Äì AND, ph√¢n bi·ªát d·∫•u)")

    # Tokenize t√™n: GI·ªÆ d·∫•u ti·∫øng Vi·ªát, t√°ch th√†nh c√°c "t·ª´" unicode (a‚Äìz, 0‚Äì9, v√† ch·ªØ c√≥ d·∫•u)
    def name_tokens_vn(s: str):
        s = "" if s is None else str(s).lower()
        return re.findall(r"[0-9A-Za-z√Ä-·ªπ]+", s)

    # T√°ch truy v·∫•n th√†nh c√°c "t·ª´" (tokens) ‚Äì h·ªó tr·ª£ nhi·ªÅu t·ª´ => ƒëi·ªÅu ki·ªán AND
    def query_tokens_vn(q: str):
        q = (q or "").strip().lower()
        # H·ªó tr·ª£ ngƒÉn c√°ch b·∫±ng kho·∫£ng tr·∫Øng ho·∫∑c d·∫•u ph·∫©y
        qs = re.split(r"[,\s]+", q)
        return [t for t in qs if t]

    q_raw = st.text_input("Nh·∫≠p t·ª´ kh√≥a (v√≠ d·ª•: 'an', 'ƒë·∫°t', 'nam vƒÉn', '73', 'TRY', 'BVY', 'Tr∆∞·ªùng Y', 'BV ƒêHYD')").strip()
    if q_raw:
        base = df.copy()
        base["__name_tokens"] = base.get("H·ªç t√™n", "").astype(str).apply(name_tokens_vn)
        base["__plate_norm"]  = base.get("Bi·ªÉn s·ªë", "").astype(str).apply(normalize_plate)
        base["__unit_code"]   = base.get("M√£ ƒë∆°n v·ªã", "").astype(str).str.upper().str.strip()
        base["__card_code"]   = base.get("M√£ th·∫ª", "").astype(str).str.upper().str.strip()

        q_up    = q_raw.upper()
        q_tokens = query_tokens_vn(q_raw)

        res = base

        # 1) N·∫øu to√†n s·ªë ‚Üí l·ªçc bi·ªÉn s·ªë CH·ª®A chu·ªói s·ªë ƒë√≥ (v√≠ d·ª• '73')
        if re.fullmatch(r"\d{2,}", q_raw):
            res = res[res["__plate_norm"].str.contains(q_raw, na=False)]
        else:
            # 2) M√£ ƒë∆°n v·ªã / m√£ th·∫ª (∆∞u ti√™n)
            if q_up in DON_VI_MAP.values():                # v√≠ d·ª• TRY, BVY
                res = res[res["__unit_code"].eq(q_up)]
            elif re.fullmatch(r"[A-Z]{3}\d{3}", q_up):     # v√≠ d·ª• TRY012
                res = res[res["__card_code"].eq(q_up)]
            else:
                # 3) T√™n ƒë∆°n v·ªã chu·∫©n (kh√¥ng fuzzy)
                if q_up in map(str.upper, DON_VI_MAP.keys()):
                    res = res[res["T√™n ƒë∆°n v·ªã"].str.upper().eq(q_up)]
                else:
                    # 4) M·∫∑c ƒë·ªãnh: AND tr√™n c√°c token h·ªç t√™n (GI·ªÆ d·∫•u, T·ª™ tr·ªçn v·∫πn)
                    #    - 'an' ch·ªâ kh·ªõp token 'an' (kh√¥ng kh·ªõp '√¢n', '·∫©n', 'khang'‚Ä¶)
                    #    - 'ƒë·∫°t' kh·ªõp ƒë√∫ng 'ƒë·∫°t'
                    #    - 'nam vƒÉn' y√™u c·∫ßu c·∫£ 'nam' v√† 'vƒÉn' ƒë·ªÅu xu·∫•t hi·ªán trong t√™n
                    qset = set(q_tokens)
                    res = res[res["__name_tokens"].apply(lambda toks: qset.issubset(set(toks)))]

        res = res.drop(columns=["__name_tokens","__plate_norm","__unit_code","__card_code"], errors="ignore")

        if res.empty:
            st.info("Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ tr√πng kh·ªõp.")
        else:
            st.success(f"T√¨m th·∫•y {len(res)} k·∫øt qu·∫£.")
            st.dataframe(res, hide_index=True, use_container_width=True)


# ---------- Footer ----------
st.markdown("""
<hr style='margin-top:50px; margin-bottom:20px;'>

<div style='font-size:14px; line-height:1.6; text-align:center; color:#444;'>
    <strong>Ph√≤ng H√†nh ch√≠nh T·ªïng H·ª£p - ƒê·∫°i h·ªçc Y D∆∞·ª£c Th√†nh ph·ªë H·ªì Ch√≠ Minh</strong><br>
    ƒê·ªãa ch·ªâ: 217 H·ªìng B√†ng, Ph∆∞·ªùng Ch·ª£ L·ªõn, TP. H·ªì Ch√≠ Minh<br>
    ƒêT: (+84-28) 3855 8411 - (+84-28) 3853 7949 - (+84-28) 3855 5780<br>
    Fax: (+84-28) 3855 2304<br>
    Email: <a href='mailto:hanhchinh@ump.edu.vn'>hanhchinh@ump.edu.vn</a><br><br>
    <em>Copyright ¬© 2025 B·∫£n quy·ªÅn thu·ªôc v·ªÅ Ph√≤ng H√†nh ch√≠nh T·ªïng H·ª£p - ƒê·∫°i h·ªçc Y D∆∞·ª£c Th√†nh ph·ªë H·ªì Ch√≠ Minh</em>
</div>
""", unsafe_allow_html=True)
