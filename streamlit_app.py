import streamlit as st
import pandas as pd
import urllib.parse
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import qrcode
import re
from PIL import Image
from io import BytesIO
import difflib
import zipfile
import io
# ==== DROP-IN: bulk upload fixed (no UI changes) ====
import re, time, random
import pandas as pd

END_COL = "I"  # n·∫øu sheet c·ªßa b·∫°n c√≥ nhi·ªÅu/√≠t c·ªôt h∆°n, ƒë·ªïi ch·ªØ c√°i c·ªôt cu·ªëi

def _canon(s):
    import unicodedata
    s = "" if s is None else str(s)
    s = unicodedata.normalize("NFD", s)
    s = "".join(ch for ch in s if unicodedata.category(ch) != "Mn")
    s = re.sub(r"[^A-Za-z0-9]+", "", s).lower()
    return s

_CANON2STD = {
    "stt":"STT","hoten":"H·ªç t√™n","name":"H·ªç t√™n","hovaten":"H·ªç t√™n","ten":"H·ªç t√™n",
    "bienso":"Bi·ªÉn s·ªë","licenseplate":"Bi·ªÉn s·ªë","plate":"Bi·ªÉn s·ªë","biensoxe":"Bi·ªÉn s·ªë",
    "mathe":"M√£ th·∫ª","ma_the":"M√£ th·∫ª",
    "madonvi":"M√£ ƒë∆°n v·ªã","tendonvi":"T√™n ƒë∆°n v·ªã",
    "chucvu":"Ch·ª©c v·ª•","sodienthoai":"S·ªë ƒëi·ªán tho·∫°i","dienthoai":"S·ªë ƒëi·ªán tho·∫°i","phone":"S·ªë ƒëi·ªán tho·∫°i",
    "email":"Email",
}
REQ = ["STT","H·ªç t√™n","Bi·ªÉn s·ªë","M√£ th·∫ª","M√£ ƒë∆°n v·ªã","T√™n ƒë∆°n v·ªã","Ch·ª©c v·ª•","S·ªë ƒëi·ªán tho·∫°i","Email"]

def coerce_columns(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty: return df
    ren, seen = {}, set()
    for c in df.columns:
        std = _CANON2STD.get(_canon(c))
        if std and std not in seen:
            ren[c] = std; seen.add(std)
    out = df.rename(columns=ren).copy()
    for c in REQ:
        if c not in out.columns: out[c] = ""
    return out

CARD_PREFIX, CARD_PAD = "TH", 6
def _slug_unit(name: str) -> str:
    if not isinstance(name, str) or not name.strip(): return "DV"
    words = re.findall(r"[A-Za-z√Ä-·ªπ0-9]+", name.strip(), flags=re.UNICODE)
    if not words: return "DV"
    initials = "".join(w[0] for w in words).upper()
    if len(initials) <= 1:
        flat = re.sub(r"[^A-Za-z0-9]", "", name.upper())
        return (flat or "DV")[:8]
    return initials[:8]

def _next_card_seed(series: pd.Series) -> int:
    mx = 0
    for v in (series or pd.Series(dtype=str)).dropna().astype(str):
        m = re.match(rf"^{re.escape(CARD_PREFIX)}(\d+)$", v.strip(), flags=re.IGNORECASE)
        if m:
            try: mx = max(mx, int(m.group(1)))
            except: pass
    return mx

def ensure_codes_all(df_up: pd.DataFrame, df_cur: pd.DataFrame) -> pd.DataFrame:
    df_up = coerce_columns(df_up).dropna(how="all").reset_index(drop=True)
    df_cur = coerce_columns(df_cur if df_cur is not None else pd.DataFrame(columns=REQ))

    import unicodedata, re as _re

    # ===== Aliases ƒë·ªÉ b·∫Øt c√°c bi·∫øn th·ªÉ v·∫´n ƒë√∫ng l√† 1 ƒë∆°n v·ªã =====
    UNIT_ALIASES = {
        # BV ƒêHYD
        "bvdhyd": "BV ƒêHYD",
        "bv dhyd": "BV ƒêHYD",
        "bvƒëhyd": "BV ƒêHYD",
        "bvdvyd": "BV ƒêHYD",   # hay nh·∫ßm 'H' -> 'V'
        "bv ƒëvyd": "BV ƒêHYD",

        # RHM
        "rhm": "RHM",
        "rmh": "RHM",          # ƒë·∫£o ch·ªØ c√°i
    }

    def _canon_name(s):
        s = "" if s is None else str(s)
        s = unicodedata.normalize("NFD", s)
        s = "".join(ch for ch in s if unicodedata.category(ch) != "Mn")
        s = _re.sub(r"\s+", " ", s).strip().lower()
        return s

    def _is_blank(v) -> bool:
        if v is None: return True
        s = str(v).strip()
        if s == "": return True
        return s.lower() in {"nan", "none", "null", "na", "n/a", "-", "_"}

    # 1) Map t√™n -> m√£ ƒë∆°n v·ªã
    canon_from_const = { _canon_name(k): v for k, v in DON_VI_MAP.items() }  # d√πng ch√≠nh DON_VI_MAP c·ªßa b·∫°n
    unit_map_sheet = {}
    if not df_cur.empty and all(c in df_cur.columns for c in ["T√™n ƒë∆°n v·ªã","M√£ ƒë∆°n v·ªã"]):
        for _, r in df_cur[["T√™n ƒë∆°n v·ªã","M√£ ƒë∆°n v·ªã"]].dropna().iterrows():
            name = str(r["T√™n ƒë∆°n v·ªã"]).strip().upper()
            code = str(r["M√£ ƒë∆°n v·ªã"]).strip().upper()
            if name and code:
                unit_map_sheet[name] = code

    used_units = set(df_cur.get("M√£ ƒë∆°n v·ªã", pd.Series(dtype=str)).dropna().astype(str).str.upper())

    def _slug_unit(name: str) -> str:
        if not isinstance(name, str) or not name.strip(): return "DV"
        words = _re.findall(r"[A-Za-z√Ä-·ªπ0-9]+", name.strip(), flags=_re.UNICODE)
        if not words: return "DV"
        initials = "".join(w[0] for w in words).upper()
        if len(initials) <= 1:
            flat = _re.sub(r"[^A-Za-z0-9]", "", name.upper())
            return (flat or "DV")[:8]
        return initials[:8]

    def resolve_unit_code(ten):
        if _is_blank(ten):
            return _slug_unit("")
        ckey = _canon_name(ten)
        # a) Alias -> t√™n chu·∫©n -> DON_VI_MAP
        if ckey in UNIT_ALIASES:
            std_name = UNIT_ALIASES[ckey]
            return DON_VI_MAP.get(std_name, _slug_unit(std_name))
        # b) DON_VI_MAP tr·ª±c ti·∫øp
        if ckey in canon_from_const:
            return canon_from_const[ckey]
        # c) T√™n tr√πng d·ªØ li·ªáu ƒëang c√≥
        key_up = str(ten).strip().upper()
        if key_up in unit_map_sheet:
            return unit_map_sheet[key_up]
        # d) Fallback slug (tr√°nh tr√πng)
        base, cand, k = _slug_unit(str(ten)), None, 2
        cand = base
        while cand.upper() in used_units:
            cand = f"{base}{k}"; k += 1
        used_units.add(cand.upper())
        return cand

    # 2) Seed s·ªë th·ª© t·ª± m√£ th·∫ª theo t·ª´ng ƒë∆°n v·ªã (KHB001‚Ä¶, TRY001‚Ä¶)
    CARD_PAD = 3
    per_unit_seed = {}
    if not df_cur.empty and all(c in df_cur.columns for c in ["M√£ ƒë∆°n v·ªã","M√£ th·∫ª"]):
        for uc, grp in df_cur.groupby(df_cur["M√£ ƒë∆°n v·ªã"].astype(str).str.upper(), dropna=True):
            mx = 0
            for v in grp["M√£ th·∫ª"].dropna().astype(str):
                m = _re.match(rf"^{_re.escape(uc)}(\d+)$", v.strip(), flags=_re.IGNORECASE)
                if m:
                    try: mx = max(mx, int(m.group(1)))
                    except: pass
            per_unit_seed[uc] = mx

    # 3) G√°n M√£ ƒë∆°n v·ªã + M√£ th·∫ª (lu√¥n √©p theo DON_VI_MAP/ALIASES n·∫øu t√™n ƒë∆°n v·ªã kh·ªõp)
    for i, r in df_up.iterrows():
        ten_dv = r.get("T√™n ƒë∆°n v·ªã", "")
        target_uc = resolve_unit_code(ten_dv)  # <-- m√£ ƒë∆°n v·ªã ƒë√≠ch theo quy ∆∞·ªõc
        df_up.at[i, "M√£ ƒë∆°n v·ªã"] = target_uc   # ghi ƒë√® ƒë·ªÉ s·ª≠a m·ªçi l·ªách m√£ c√≥ s·∫µn

        ma_the = r.get("M√£ th·∫ª", "")
        if _is_blank(ma_the):
            uc = str(target_uc).strip().upper()
            if uc not in per_unit_seed:
                per_unit_seed[uc] = 0
            per_unit_seed[uc] += 1
            df_up.at[i, "M√£ th·∫ª"] = f"{uc}{str(per_unit_seed[uc]).zfill(CARD_PAD)}"

    return df_up

def gs_retry(func, *args, max_retries=7, base=0.6, **kwargs):
    for i in range(max_retries):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            code = getattr(getattr(e, "response", None), "status_code", None)
            if code in (429,500,503):
                time.sleep(base*(2**i) + random.uniform(0,0.5))
                continue
            raise
    raise RuntimeError("Google Sheets write failed after multiple retries")

def write_bulk(sheet, df_cur: pd.DataFrame, df_new: pd.DataFrame, chunk_rows=200, pause=0.5):
    """Ghi theo block ƒë·ªÉ tr√°nh quota; t·ª± sinh m√£ tr∆∞·ªõc khi ghi."""
    df_cur = coerce_columns(df_cur)
    df_new = ensure_codes_all(df_new, df_cur)
    values = df_new.fillna("").astype(object).values.tolist()
    start = len(df_cur) + 2
    written = 0
    for i in range(0, len(values), chunk_rows):
        block = values[i:i+chunk_rows]
        rng = f"A{start+i}:{END_COL}{start+i+len(block)-1}"
        gs_retry(sheet.update, rng, block)
        written += len(block)
        time.sleep(pause)
    return written
def _get_query_params():
    try:
        return st.query_params
    except Exception:
        return st.experimental_get_query_params()

def _normalize_plate(s: str) -> str:
    import re
    s = "" if s is None else str(s).upper()
    return re.sub(r"[^A-Z0-9]", "", s)

def qr_gate_and_show(df_cur):
    q = _get_query_params()
    raw_id = (q.get("id") or [""])[0] if isinstance(q, dict) else q.get("id", "")
    id_ = str(raw_id).strip()
    if not id_:
        return False  # kh√¥ng ·ªü ch·∫ø ƒë·ªô QR

    # C·ªïng QR d√πng secrets
    if not st.session_state.get("_qr_ok"):
        pw = st.text_input("üîë Nh·∫≠p m·∫≠t kh·∫©u ƒë·ªÉ xem th√¥ng tin xe", type="password", key="_qr_pw")
        if pw:
            if pw == st.secrets["qr_password"]:
                st.session_state["_qr_ok"] = True
                st.rerun()
            else:
                st.error("‚ùå M·∫≠t kh·∫©u QR sai.")
                st.stop()
        st.stop()

    # T√¨m ƒë√∫ng d√≤ng: ∆∞u ti√™n M√£ th·∫ª, fallback Bi·ªÉn s·ªë
    sel = df_cur[df_cur["M√£ th·∫ª"].astype(str).str.upper() == id_.upper()]
    if sel.empty and "Bi·ªÉn s·ªë" in df_cur:
        sel = df_cur[df_cur["Bi·ªÉn s·ªë"].astype(str).map(_normalize_plate) == _normalize_plate(id_)]

    if sel.empty:
        st.error("‚ùå Kh√¥ng t√¨m th·∫•y xe.")
    else:
        st.success("‚úÖ X√°c th·ª±c OK")
        st.dataframe(sel, hide_index=True)
    st.stop()

# ---------- Page config ----------
import re as _re_patch, unicodedata as _unicodedata_patch, time as _time_patch, random as _random_patch
import pandas as _pd_patch

def _canon_ap(a):
    if a is None: return ""
    s = str(a)
    s = _unicodedata_patch.normalize("NFD", s)
    s = "".join(ch for ch in s if _unicodedata_patch.category(ch) != "Mn")
    s = s.lower()
    s = _re_patch.sub(r"[^a-z0-9]+", "", s)
    return s

_AP_CANON_TO_STD = {
    "bienso": "Bi·ªÉn s·ªë",
    "biensoxe": "Bi·ªÉn s·ªë",
    "licenseplate": "Bi·ªÉn s·ªë",
    "plate": "Bi·ªÉn s·ªë",
    "hoten": "H·ªç t√™n",
    "ten": "H·ªç t√™n",
    "hovaten": "H·ªç t√™n",
    "fullname": "H·ªç t√™n",
    "name": "H·ªç t√™n",
    "sodienthoai": "S·ªë ƒëi·ªán tho·∫°i",
    "dienthoai": "S·ªë ƒëi·ªán tho·∫°i",
    "phone": "S·ªë ƒëi·ªán tho·∫°i",
    "email": "Email",
    "madonvi": "M√£ ƒë∆°n v·ªã",
    "tendonvi": "T√™n ƒë∆°n v·ªã",
    "chucvu": "Ch·ª©c v·ª•",
    "mathe": "M√£ th·∫ª",
    "ma_the": "M√£ th·∫ª",
}

_AP_REQUIRED_COLUMNS = ["STT","H·ªç t√™n","Bi·ªÉn s·ªë","M√£ th·∫ª","M√£ ƒë∆°n v·ªã","T√™n ƒë∆°n v·ªã","Ch·ª©c v·ª•","S·ªë ƒëi·ªán tho·∫°i","Email"]

def coerce_columns(df):
    try:
        if df is None or getattr(df, "empty", False):
            return df
    except Exception:
        return df
    ren = {}
    seen = set()
    for c in list(df.columns):
        k = _canon_ap(c)
        std = _AP_CANON_TO_STD.get(k)
        if std and std not in seen:
            ren[c] = std
            seen.add(std)
    out = df.rename(columns=ren)
    for col in _AP_REQUIRED_COLUMNS:
        if col not in out.columns:
            out[col] = ""
    return out

def safe_format_plate(x):
    if _pd_patch.isna(x) or str(x).strip() == "":
        return ""
    try:
        return dinh_dang_bien_so(str(x))
    except Exception:
        return str(x)

_UNIT_PAD   = 0
_CARD_PREFIX= "TH"
_CARD_PAD   = 6

def _slug_unit(name: str) -> str:
    if not isinstance(name, str) or not name.strip():
        return "DV"
    words = _re_patch.findall(r"[A-Za-z√Ä-·ªπ0-9]+", name.strip(), flags=_re_patch.UNICODE)
    if not words:
        return "DV"
    initials = "".join(w[0] for w in words).upper()
    if len(initials) <= 1:
        flat = _re_patch.sub(r"[^A-Za-z0-9]", "", name.upper())
        return (flat or "DV")[:8]
    return initials[:8]

def _next_card_seed(existing_codes):
    max_num = 0
    try:
        it = _pd_patch.Series(existing_codes).dropna().astype(str)
    except Exception:
        it = []
    for v in it:
        m = _re_patch.match(rf"^{_re_patch.escape(_CARD_PREFIX)}(\d+)$", v.strip(), flags=_re_patch.IGNORECASE)
        if m:
            try:
                max_num = max(max_num, int(m.group(1)))
            except:
                pass
    return max_num

def ensure_codes(df_up, df_cur):
    df_up = coerce_columns(df_up)
    df_cur = coerce_columns(df_cur) if df_cur is not None else _pd_patch.DataFrame(columns=_AP_REQUIRED_COLUMNS)
    df_cur = coerce_columns(df_cur)
    unit_map = {}
    if not getattr(df_cur, "empty", True) and all(c in df_cur.columns for c in ["T√™n ƒë∆°n v·ªã","M√£ ƒë∆°n v·ªã"]):
        for _, r in df_cur[["T√™n ƒë∆°n v·ªã","M√£ ƒë∆°n v·ªã"]].dropna().iterrows():
            name = str(r["T√™n ƒë∆°n v·ªã"]).strip().upper()
            code = str(r["M√£ ƒë∆°n v·ªã"]).strip().upper()
            if name and code:
                unit_map[name] = code
    used_unit = set(df_cur["M√£ ƒë∆°n v·ªã"].dropna().astype(str).str.upper()) if "M√£ ƒë∆°n v·ªã" in df_cur.columns else set()

    def _alloc_unit(ten: str) -> str:
        if not ten: return "DV"
        key = ten.strip().upper()
        if key in unit_map: return unit_map[key]
        base = _slug_unit(ten)
        cand = base
        k = 2
        while cand.upper() in used_unit:
            cand = f"{base}{(str(k).zfill(_UNIT_PAD)) if _UNIT_PAD>0 else k}"; k += 1
        used_unit.add(cand.upper())
        unit_map[key] = cand
        return cand

    start_num = _next_card_seed(df_cur.get("M√£ th·∫ª") if "M√£ th·∫ª" in df_cur.columns else _pd_patch.Series(dtype=str))
    cur_num = start_num
    def _alloc_card() -> str:
        nonlocal cur_num
        cur_num += 1
        return f"{_CARD_PREFIX}{str(cur_num).zfill(_CARD_PAD)}"

    for i, r in df_up.iterrows():
        if not str(r.get("M√£ ƒë∆°n v·ªã","")).strip():
            df_up.at[i, "M√£ ƒë∆°n v·ªã"] = _alloc_unit(str(r.get("T√™n ƒë∆°n v·ªã","")).strip())
        if not str(r.get("M√£ th·∫ª","")).strip():
            df_up.at[i, "M√£ th·∫ª"] = _alloc_card()
    return df_up

def gs_retry(func, *args, max_retries=6, base=0.8, **kwargs):
    for i in range(max_retries):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            code = getattr(getattr(e, "response", None), "status_code", None)
            if code in (429,500,503):
                _time_patch.sleep(base*(2**i) + _random_patch.uniform(0,0.5))
                continue
            raise
    raise RuntimeError("Google Sheets write failed after multiple retries")
# ==== END INLINED HELPERS ====

st.set_page_config(page_title="QR Car Management", page_icon="üöó", layout="wide")

# ---------- Constants ----------
REQUIRED_COLUMNS = ["STT", "H·ªç t√™n", "Bi·ªÉn s·ªë", "M√£ th·∫ª", "M√£ ƒë∆°n v·ªã", "T√™n ƒë∆°n v·ªã", "Ch·ª©c v·ª•", "S·ªë ƒëi·ªán tho·∫°i", "Email"]
DON_VI_MAP = {
    "HCTH": "HCT", "TCCB": "TCC", "ƒêTƒêH": "DTD", "ƒêTSƒêH": "DTS", "KHCN": "KHC", "KHTC": "KHT",
    "QTGT": "QTG", "TTPC": "TTP", "ƒêBCLGD&KT": "DBK", "CTSV": "CTS", "Tr∆∞·ªùng Y": "TRY",
    "Tr∆∞·ªùng D∆∞·ª£c": "TRD", "Tr∆∞·ªùng ƒêD-KTYH": "TRK", "KHCB": "KHB", "RHM": "RHM", "YTCC": "YTC",
    "PK.CKRHM": "CKR", "TT.KCCLXN": "KCL", "TT.PTTN": "PTN", "TT.ƒêTNLYT": "DTL", "TT.CNTT": "CNT",
    "TT.KHCN UMP": "KCU", "TT.YSHPT": "YSH", "Th∆∞ vi·ªán": "TV", "KTX": "KTX", "T·∫°p ch√≠ Y h·ªçc": "TCY",
    "BV ƒêHYD": "BVY", "TT. GDYH": "GDY", "VPƒê": "VPD", "YHCT": "YHC", "HTQT": "HTQ"
}
# Chu·∫©n ho√° kh√¥ng d·∫•u ƒë·ªÉ b·∫Øt c√°c bi·∫øn th·ªÉ th∆∞·ªùng g√µ nh·∫ßm
UNIT_ALIASES = {
    # B·ªánh vi·ªán ƒêHYD (BVY)
    "bvdhyd": "BV ƒêHYD",
    "bv dhyd": "BV ƒêHYD",
    "bvƒëhyd": "BV ƒêHYD",
    "bvdvyd": "BV ƒêHYD",     # hay g√µ nh·∫ßm V/H
    "bv ƒëvyd": "BV ƒêHYD",

    # RHM
    "rhm": "RHM",
    "rmh": "RHM",            # ƒë·∫£o ch·ªØ c√°i
}

# ---------- Helpers ----------
def normalize_plate(plate: str) -> str:
    return re.sub(r'[^a-zA-Z0-9]', '', str(plate)).lower()

def format_name(name: str) -> str:
    return ' '.join(word.capitalize() for word in str(name).strip().split())

def dinh_dang_bien_so(bs: str) -> str:
    bs = re.sub(r"[^A-Z0-9]", "", str(bs).upper())
    if len(bs) == 8:
        return f"{bs[:3]}-{bs[3:6]}.{bs[6:]}"
    return bs

def to_native_ll(df: pd.DataFrame):
    out = []
    for _, row in df.iterrows():
        items = []
        for v in row.tolist():
            if pd.isna(v):
                items.append("")
            elif isinstance(v, (int, float)):
                if isinstance(v, float) and v.is_integer():
                    items.append(int(v))
                else:
                    items.append(float(v) if isinstance(v, float) else int(v))
            else:
                items.append(str(v))
        out.append(items)
    return out

def ensure_columns(df: pd.DataFrame):
    missing = [c for c in REQUIRED_COLUMNS if c not in df.columns]
    if missing:
        raise ValueError(f"Thi·∫øu c·ªôt b·∫Øt bu·ªôc: {', '.join(missing)}")
    return df[REQUIRED_COLUMNS].copy()

def resolve_ma_don_vi(ten_don_vi: str, ma_don_vi_cur: str = "") -> str:
    if str(ma_don_vi_cur).strip():
        return str(ma_don_vi_cur).strip().upper()
    name = str(ten_don_vi).strip()
    return DON_VI_MAP.get(name, "").upper()

def build_unit_counters(df_cur: pd.DataFrame) -> dict:
    counters = {}
    if "M√£ th·∫ª" in df_cur.columns:
        for val in df_cur["M√£ th·∫ª"].dropna().astype(str):
            m = re.match(r"^([A-Z]{3})(\d{3})$", val.strip().upper())
            if m:
                unit = m.group(1)
                num = int(m.group(2))
                counters[unit] = max(counters.get(unit, 0), num)
    return counters

def assign_codes_for_row(row: pd.Series, counters: dict) -> pd.Series:
    ma_dv = resolve_ma_don_vi(row.get("T√™n ƒë∆°n v·ªã", ""), row.get("M√£ ƒë∆°n v·ªã", ""))
    row["M√£ ƒë∆°n v·ªã"] = ma_dv
    ma_the = str(row.get("M√£ th·∫ª", "") or "").strip().upper()
    if not ma_dv:
        return row
    if not ma_the:
        cur = counters.get(ma_dv, 0) + 1
        counters[ma_dv] = cur
        row["M√£ th·∫ª"] = f"{ma_dv}{cur:03d}"
    else:
        m = re.match(rf"^{ma_dv}(\d{{3}})$", ma_the)
        if m:
            counters[ma_dv] = max(counters.get(ma_dv, 0), int(m.group(1)))
        row["M√£ th·∫ª"] = ma_the
    return row

def reindex_stt(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df["STT"] = list(range(1, len(df) + 1))
    return df

def make_qr_bytes(url: str) -> bytes:
    img = qrcode.make(url)
    buf = BytesIO()
    img.save(buf)
    buf.seek(0)
    return buf.getvalue()

# ---------- Lightweight "AI" helpers ----------
def fuzzy_ratio(a: str, b: str) -> float:
    return difflib.SequenceMatcher(None, str(a).lower(), str(b).lower()).ratio()

def fuzzy_search_df(df: pd.DataFrame, query: str, topk: int = 50):
    if df.empty or not str(query).strip():
        return df.copy()
    scores = []
    for idx, row in df.iterrows():
        s = 0.0
        s += 2.0 * fuzzy_ratio(query, row.get("Bi·ªÉn s·ªë", ""))
        s += fuzzy_ratio(query, row.get("H·ªç t√™n", ""))
        s += fuzzy_ratio(query, row.get("M√£ th·∫ª", ""))
        s += 0.8 * fuzzy_ratio(query, row.get("T√™n ƒë∆°n v·ªã", ""))
        s += 0.8 * fuzzy_ratio(query, row.get("M√£ ƒë∆°n v·ªã", ""))
        s += 0.5 * fuzzy_ratio(query, row.get("S·ªë ƒëi·ªán tho·∫°i", ""))
        s += 0.6 * fuzzy_ratio(query, row.get("Email", ""))
        scores.append((idx, s))
    scores.sort(key=lambda x: x[1], reverse=True)
    idxs = [i for i, _ in scores[:topk]]
    out = df.loc[idxs].copy()
    out["__score__"] = [sc for _, sc in scores[:topk]]
    return out.sort_values("__score__", ascending=False)

def simple_query_parser(q: str):
    q = str(q).strip()
    tokens = re.findall(r"[\w√Ä-·ªπ]+", q, flags=re.IGNORECASE)
    keys = {"unit": None, "plate": None, "name": None, "email": None, "phone": None}
    m_email = re.search(r"[\w\.-]+@[\w\.-]+", q)
    if m_email: keys["email"] = m_email.group(0)
    m_phone = re.search(r"(0\d{8,11})", q)
    if m_phone: keys["phone"] = m_phone.group(1)
    best_unit = None; best_score = 0
    for t in tokens:
        for name in DON_VI_MAP.keys():
            sc = fuzzy_ratio(t, name)
            if sc > best_score and sc > 0.75:
                best_unit = name; best_score = sc
    keys["unit"] = best_unit
    plate_like = [t for t in tokens if re.search(r"[A-Za-z].*\d|\d.*[A-Za-z]", t)]
    if plate_like:
        keys["plate"] = plate_like[0]
    if not keys["email"] and not keys["phone"] and not keys["plate"]:
        if tokens:
            keys["name"] = max(tokens, key=len)
    return keys

def filter_with_keys(df: pd.DataFrame, keys: dict):
    cur = df.copy()
    applied = False
    if keys.get("unit"):
        cur = cur[cur["T√™n ƒë∆°n v·ªã"].astype(str).str.contains(keys["unit"], case=False, regex=False)]
        applied = True
    if keys.get("email"):
        cur = cur[cur["Email"].astype(str).str.contains(keys["email"], case=False, regex=False)]
        applied = True
    if keys.get("phone"):
        cur = cur[cur["S·ªë ƒëi·ªán tho·∫°i"].astype(str).str.contains(keys["phone"], case=False, regex=False)]
        applied = True
    if keys.get("plate"):
        norm = normalize_plate(keys["plate"])
        cur["__norm"] = cur["Bi·ªÉn s·ªë"].astype(str).apply(normalize_plate)
        cur = cur[cur["__norm"].str.contains(norm, na=False)]
        cur = cur.drop(columns=["__norm"], errors="ignore")
        applied = True
    if keys.get("name"):
        cur = cur[cur["H·ªç t√™n"].astype(str).str.contains(keys["name"], case=False, regex=False)]
        applied = True
    return cur, applied

# ---------- Secrets: m·∫≠t kh·∫©u ·ª©ng d·ª•ng ----------
APP_PASSWORD = st.secrets.get("app_password") or st.secrets.get("qr_password")
if not APP_PASSWORD:
    st.error("‚ùå Thi·∫øu m·∫≠t kh·∫©u ·ª©ng d·ª•ng trong secrets (app_password ho·∫∑c qr_password).")
    st.stop()

# ---------- Google Sheet init (gi·ªØ nguy√™n secrets/JSON) ----------
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
if "google_service_account" not in st.secrets:
    st.error("‚ùå Thi·∫øu [google_service_account] trong secrets.")
    st.stop()
try:
    creds_dict = dict(st.secrets["google_service_account"])  # kh√¥ng ƒë·ªïi c·∫•u tr√∫c
    pk = str(creds_dict.get("private_key", ""))
    if ("-----BEGIN" in pk) and ("\\n" in pk) and ("\n" not in pk):
        pk = pk.replace("\\r\\n", "\\n").replace("\\n", "\n")
        creds_dict["private_key"] = pk
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    client = gspread.authorize(creds)
except Exception as e:
    st.error(f"‚ùå L·ªói kh·ªüi t·∫°o Google Credentials: {e}")
    st.stop()

# Thay b·∫±ng Sheet c·ªßa b·∫°n
SHEET_ID = "1a_pMNiQbD5yO58abm4EfNMz7AbQTBmG8QV3yEN500uc"
try:
    sheet = client.open_by_key(SHEET_ID).worksheet("Sheet1")
except Exception as e:
    st.error(f"‚ùå L·ªói m·ªü Google Sheet: {e}")
    st.stop()

# ---------- Load data ----------
@st.cache_data(ttl=60)
def load_df():
    try:
        data = sheet.get_all_records()
        return pd.DataFrame(data)
    except Exception as e:
        st.error(f"‚ùå Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu xe: {e}")
        st.stop()

# ---------- QR GUARD (cho lu·ªìng qu√©t QR) ----------
bien_so_url = st.query_params.get("id", "")
if bien_so_url:
    # ·∫®n sidebar & nav ƒë·ªÉ ng∆∞·ªùi qu√©t kh√¥ng th·∫•y c√°c tab
    st.markdown("""
        <style>
            [data-testid="stSidebar"] {display: none !important;}
            [data-testid="stSidebarNav"] {display: none !important;}
            [data-testid="stSidebarContent"] {display: none !important;}
        </style>
    """, unsafe_allow_html=True)

    st.subheader("üîç Tra c·ª©u xe b·∫±ng m√£ QR")
    mat_khau = st.text_input("üîë Nh·∫≠p m·∫≠t kh·∫©u ƒë·ªÉ xem th√¥ng tin xe", type="password")
    if mat_khau:
        if mat_khau.strip() != str(APP_PASSWORD):
            st.error("‚ùå Sai m·∫≠t kh·∫©u!")
        else:
            df = load_df()
            df_tmp = df.copy()
            df_tmp["__norm"] = df_tmp["Bi·ªÉn s·ªë"].astype(str).apply(normalize_plate)
            ket_qua = df_tmp[df_tmp["__norm"] == normalize_plate(bien_so_url)]
            if ket_qua.empty:
                st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y xe c√≥ bi·ªÉn s·ªë: {bien_so_url}")
            else:
                st.success("‚úÖ Th√¥ng tin xe:")
                st.dataframe(ket_qua.drop(columns=["__norm"]), use_container_width=True)
        st.stop()
    else:
        st.info("Vui l√≤ng nh·∫≠p m·∫≠t kh·∫©u ƒë·ªÉ xem th√¥ng tin xe.")
        st.stop()

# ---------- App login gate ----------
if "auth_ok" not in st.session_state:
    st.session_state.auth_ok = False

# Logo + ti√™u ƒë·ªÅ (ch·ªâ hi·ªán sau login, nh∆∞ng ƒë·ªÉ ƒë·∫πp, ta hi·ªán lu√¥n ti√™u ƒë·ªÅ)
st.markdown("<h1 style='text-align:center; color:#004080;'>üöó QR Car Management</h1>", unsafe_allow_html=True)

if not st.session_state.auth_ok:
    st.markdown("### üîê ƒêƒÉng nh·∫≠p")
    pwd = st.text_input("M·∫≠t kh·∫©u", type="password")
    if st.button("ƒêƒÉng nh·∫≠p"):
        if pwd.strip() == str(APP_PASSWORD):
            st.session_state.auth_ok = True
            st.success("‚úÖ ƒêƒÉng nh·∫≠p th√†nh c√¥ng.")
        else:
            st.error("‚ùå Sai m·∫≠t kh·∫©u!")
    st.stop()

# ---------- Sau khi ƒëƒÉng nh·∫≠p: sidebar + d·ªØ li·ªáu ----------
st.sidebar.image("ump_logo.png", width=120)
st.sidebar.markdown("---")

if "df" not in st.session_state:
    st.session_state.df = load_df()
df = st.session_state.df

# ---------- Menu sau ƒëƒÉng nh·∫≠p ----------
menu = [
    "üìã Xem danh s√°ch",
    "üîç T√¨m ki·∫øm xe",
    "‚ûï ƒêƒÉng k√Ω xe m·ªõi",
    "‚úèÔ∏è C·∫≠p nh·∫≠t xe",
    "üóëÔ∏è X√≥a xe",
    "üì• T·∫£i d·ªØ li·ªáu l√™n",
    "üì§ Xu·∫•t ra Excel",
    "üìä Th·ªëng k√™ xe theo ƒë∆°n v·ªã",
    "üéÅ T·∫°o m√£ QR h√†ng lo·∫°t",
    "ü§ñ Tr·ª£ l√Ω AI"
]
choice = st.sidebar.radio("üìå Ch·ªçn ch·ª©c nƒÉng", menu, index=0)

# ---------- C√°c t√≠nh nƒÉng ----------
if choice == "üìã Xem danh s√°ch":
    st.subheader("üìã Danh s√°ch xe ƒë√£ ƒëƒÉng k√Ω")
    df_show = df.copy()
    df_show = coerce_columns(df_show)
    if "Bi·ªÉn s·ªë" in df_show.columns:
        df_show["Bi·ªÉn s·ªë"] = df_show["Bi·ªÉn s·ªë"].apply(safe_format_plate)
    else:
        try:
            st.warning("Kh√¥ng t√¨m th·∫•y c·ªôt 'Bi·ªÉn s·ªë' trong d·ªØ li·ªáu hi·ªÉn th·ªã.")
        except Exception:
            pass
    st.dataframe(df_show, hide_index=True)


elif choice == "üîç T√¨m ki·∫øm xe":
    st.subheader("üîç T√¨m ki·∫øm xe theo bi·ªÉn s·ªë (h·ªó tr·ª£ g·∫ßn ƒë√∫ng)")
    bien_so_input = st.text_input("Nh·∫≠p bi·ªÉn s·ªë xe c·∫ßn t√¨m")
    allow_fuzzy = st.checkbox("Cho ph√©p g·ª£i √Ω g·∫ßn ƒë√∫ng n·∫øu kh√¥ng kh·ªõp tuy·ªát ƒë·ªëi", value=True)
    if bien_so_input:
        bien_so_norm = normalize_plate(bien_so_input)
        df_tmp = df.copy()
        df_tmp["Bi·ªÉn s·ªë chu·∫©n h√≥a"] = df_tmp["Bi·ªÉn s·ªë"].astype(str).apply(normalize_plate)
        ket_qua = df_tmp[df_tmp["Bi·ªÉn s·ªë chu·∫©n h√≥a"] == bien_so_norm]
        if ket_qua.empty and allow_fuzzy:
            st.info("Kh√¥ng kh·ªõp tuy·ªát ƒë·ªëi. Th·ª≠ g·ª£i √Ω g·∫ßn ƒë√∫ng‚Ä¶")
            top = fuzzy_search_df(df, bien_so_input, topk=20)
            if top.empty:
                st.warning("üö´ Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£.")
            else:
                st.success(f"‚úÖ G·ª£i √Ω g·∫ßn ƒë√∫ng (top {len(top)}):")
                st.dataframe(top.drop(columns=["__score__"], errors="ignore"), use_container_width=True)
        elif ket_qua.empty:
            st.warning("üö´ Kh√¥ng t√¨m th·∫•y xe n√†o kh·ªõp v·ªõi bi·ªÉn s·ªë ƒë√£ nh·∫≠p.")
        else:
            st.success(f"‚úÖ T√¨m th·∫•y {len(ket_qua)} xe kh·ªõp.")
            st.dataframe(ket_qua.drop(columns=["Bi·ªÉn s·ªë chu·∫©n h√≥a"]), use_container_width=True)

elif choice == "‚ûï ƒêƒÉng k√Ω xe m·ªõi":
    st.subheader("üìã ƒêƒÉng k√Ω xe m·ªõi")
    df_current = df.copy()
    ten_don_vi = st.selectbox("Ch·ªçn ƒë∆°n v·ªã", list(DON_VI_MAP.keys()))
    ma_don_vi = DON_VI_MAP[ten_don_vi]
    col1, col2 = st.columns(2)
    with col1:
        ho_ten_raw = st.text_input("H·ªç t√™n")
        bien_so_raw = st.text_input("Bi·ªÉn s·ªë xe")
    with col2:
        chuc_vu_raw = st.text_input("Ch·ª©c v·ª•")
        so_dien_thoai = st.text_input("S·ªë ƒëi·ªán tho·∫°i")
        email = st.text_input("Email")
    ho_ten = format_name(ho_ten_raw)
    chuc_vu = format_name(chuc_vu_raw)
    bien_so = dinh_dang_bien_so(bien_so_raw)
    bien_so_da_dang_ky = df_current["Bi·ªÉn s·ªë"].dropna().apply(dinh_dang_bien_so)
    if st.button("üì• ƒêƒÉng k√Ω"):
        if bien_so in bien_so_da_dang_ky.values:
            st.error("üö´ Bi·ªÉn s·ªë n√†y ƒë√£ ƒë∆∞·ª£c ƒëƒÉng k√Ω tr∆∞·ªõc ƒë√≥!")
        elif so_dien_thoai and not str(so_dien_thoai).startswith("0"):
            st.warning("‚ö†Ô∏è S·ªë ƒëi·ªán tho·∫°i ph·∫£i b·∫Øt ƒë·∫ßu b·∫±ng s·ªë 0.")
        elif ho_ten == "" or bien_so == "":
            st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p ƒë·∫ßy ƒë·ªß th√¥ng tin.")
        else:
            try:
                # Auto m√£ th·∫ª
                counters = build_unit_counters(df_current)
                cur = counters.get(ma_don_vi, 0) + 1
                ma_the = f"{ma_don_vi}{cur:03d}"
                gs_retry(sheet.append_row, [
                    int(len(df_current) + 1),
                    ho_ten,
                    bien_so,
                    ma_the,
                    ma_don_vi,
                    ten_don_vi,
                    chuc_vu,
                    so_dien_thoai,
                    email
                ])
                st.success(f"‚úÖ ƒê√£ ƒëƒÉng k√Ω xe cho `{ho_ten}` v·ªõi m√£ th·∫ª: `{ma_the}`")
                # T·∫°o QR cho xe v·ª´a ƒëƒÉng k√Ω
                norm = normalize_plate(bien_so)
                link = f"https://qrcarump.streamlit.app/?id={urllib.parse.quote(norm)}"
                qr_png = make_qr_bytes(link)
                st.image(qr_png, caption=f"QR cho {bien_so}", width=200)
                st.download_button("üì• T·∫£i m√£ QR", data=qr_png, file_name=f"QR_{bien_so}.png", mime="image/png")
                st.caption("Qu√©t m√£ s·∫Ω y√™u c·∫ßu m·∫≠t kh·∫©u tr∆∞·ªõc khi xem th√¥ng tin.")
                # Refresh
                st.session_state.df = load_df()
            except Exception as e:
                st.error(f"‚ùå L·ªói ghi d·ªØ li·ªáu: {e}")

elif choice == "‚úèÔ∏è C·∫≠p nh·∫≠t xe":
    st.subheader("‚úèÔ∏è C·∫≠p nh·∫≠t xe")
    bien_so_input = st.text_input("Nh·∫≠p bi·ªÉn s·ªë xe c·∫ßn c·∫≠p nh·∫≠t")
    if bien_so_input:
        bien_so_norm = normalize_plate(bien_so_input)
        df_tmp = df.copy()
        df_tmp["Bi·ªÉn s·ªë chu·∫©n h√≥a"] = df_tmp["Bi·ªÉn s·ªë"].astype(str).apply(normalize_plate)
        ket_qua = df_tmp[df_tmp["Bi·ªÉn s·ªë chu·∫©n h√≥a"] == bien_so_norm]
        if ket_qua.empty:
            st.error("‚ùå Kh√¥ng t√¨m th·∫•y bi·ªÉn s·ªë xe!")
        else:
            st.success(f"‚úÖ T√¨m th·∫•y {len(ket_qua)} xe kh·ªõp.")
            st.dataframe(ket_qua.drop(columns=["Bi·ªÉn s·ªë chu·∫©n h√≥a"]), use_container_width=True)
            idx_np = ket_qua.index[0]
            index = int(idx_np)
            row = ket_qua.iloc[0]
            st.markdown("### üìù Nh·∫≠p th√¥ng tin m·ªõi ƒë·ªÉ c·∫≠p nh·∫≠t")
            col1, col2 = st.columns(2)
            with col1:
                ho_ten_moi = st.text_input("H·ªç t√™n", value=str(row["H·ªç t√™n"]))
                bien_so_moi = st.text_input("Bi·ªÉn s·ªë xe", value=str(row["Bi·ªÉn s·ªë"]))
                ten_don_vi_moi = st.text_input("T√™n ƒë∆°n v·ªã", value=str(row["T√™n ƒë∆°n v·ªã"]))
                ma_don_vi_moi = st.text_input("M√£ ƒë∆°n v·ªã", value=str(row["M√£ ƒë∆°n v·ªã"]))
            with col2:
                chuc_vu_moi = st.text_input("Ch·ª©c v·ª•", value=str(row["Ch·ª©c v·ª•"]))
                so_dien_thoai_moi = st.text_input("S·ªë ƒëi·ªán tho·∫°i", value=str(row["S·ªë ƒëi·ªán tho·∫°i"]))
                email_moi = st.text_input("Email", value=str(row["Email"]))
            if st.button("C·∫≠p nh·∫≠t"):
                try:
                    try:
                        stt_val = int(row.get("STT", ""))
                    except Exception:
                        stt_val = str(row.get("STT", ""))
                    payload = [
                        stt_val,
                        ho_ten_moi,
                        bien_so_moi,
                        str(row["M√£ th·∫ª"]),
                        ma_don_vi_moi,
                        ten_don_vi_moi,
                        chuc_vu_moi,
                        so_dien_thoai_moi,
                        email_moi
                    ]
                    gs_retry(sheet.update, f"A{index+2}:I{index+2}", [payload])
                    st.success("‚úÖ ƒê√£ c·∫≠p nh·∫≠t th√¥ng tin xe th√†nh c√¥ng!")
                    # T·∫°o QR cho xe sau c·∫≠p nh·∫≠t (d√πng bi·ªÉn s·ªë m·ªõi)
                    norm = normalize_plate(bien_so_moi)
                    link = f"https://qrcarump.streamlit.app/?id={urllib.parse.quote(norm)}"
                    qr_png = make_qr_bytes(link)
                    st.image(qr_png, caption=f"QR cho {bien_so_moi}", width=200)
                    st.download_button("üì• T·∫£i m√£ QR", data=qr_png, file_name=f"QR_{bien_so_moi}.png", mime="image/png")
                    st.caption("Qu√©t m√£ s·∫Ω y√™u c·∫ßu m·∫≠t kh·∫©u tr∆∞·ªõc khi xem th√¥ng tin.")
                    st.session_state.df = load_df()
                except Exception as e:
                    st.error(f"‚ùå L·ªói c·∫≠p nh·∫≠t: {e}")

elif choice == "üóëÔ∏è X√≥a xe":
    st.subheader("üóëÔ∏è X√≥a xe kh·ªèi danh s√°ch")
    bien_so_input = st.text_input("Nh·∫≠p bi·ªÉn s·ªë xe c·∫ßn x√≥a")
    if bien_so_input:
        try:
            bien_so_norm = normalize_plate(bien_so_input)
            df_tmp = df.copy()
            df_tmp["Bi·ªÉn s·ªë chu·∫©n h√≥a"] = df_tmp["Bi·ªÉn s·ªë"].astype(str).apply(normalize_plate)
            ket_qua = df_tmp[df_tmp["Bi·ªÉn s·ªë chu·∫©n h√≥a"] == bien_so_norm]
            if ket_qua.empty:
                st.error("‚ùå Kh√¥ng t√¨m th·∫•y bi·ªÉn s·ªë xe!")
            else:
                st.success(f"‚úÖ T√¨m th·∫•y {len(ket_qua)} xe kh·ªõp.")
                st.dataframe(ket_qua.drop(columns=["Bi·ªÉn s·ªë chu·∫©n h√≥a"]), use_container_width=True)
                idx_np = ket_qua.index[0]
                index = int(idx_np)
                row = ket_qua.iloc[0]
                if st.button("X√°c nh·∫≠n x√≥a"):
                    sheet.delete_rows(int(index) + 2)
                    st.success(f"üóëÔ∏è ƒê√£ x√≥a xe c√≥ bi·ªÉn s·ªë `{row['Bi·ªÉn s·ªë']}` th√†nh c√¥ng!")
                    st.session_state.df = load_df()
        except Exception as e:
            st.error(f"‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω: {e}")

elif choice == "üì• T·∫£i d·ªØ li·ªáu l√™n":
    st.subheader("üì• T·∫£i d·ªØ li·ªáu t·ª´ file l√™n Google Sheet")
    st.markdown("B·∫°n c√≥ th·ªÉ ƒë·ªÉ **tr·ªëng** c·ªôt **M√£ th·∫ª** v√† **M√£ ƒë∆°n v·ªã** ‚Äî h·ªá th·ªëng s·∫Ω t·ª± sinh d·ª±a tr√™n **T√™n ƒë∆°n v·ªã**.")

    # T·∫£i file m·∫´u
    tmpl = pd.DataFrame(columns=REQUIRED_COLUMNS)
    buf_tmpl = BytesIO()
    with pd.ExcelWriter(buf_tmpl, engine='openpyxl') as writer:
        tmpl.to_excel(writer, index=False, sheet_name='Template')
    st.download_button("üìÑ T·∫£i m·∫´u Excel", data=buf_tmpl.getvalue(),
                       file_name="Template_DanhSachXe.xlsx",
                       mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    file = st.file_uploader("Ch·ªçn file d·ªØ li·ªáu (.xlsx ho·∫∑c .csv)", type=["xlsx", "csv"])
    mode = st.selectbox("Ch·ªçn ch·∫ø ƒë·ªô", ["Th√™m (append)", "Thay th·∫ø to√†n b·ªô (replace all)", "C·∫≠p nh·∫≠t theo Bi·ªÉn s·ªë (upsert)"])
    auto_stt = st.checkbox("üî¢ ƒê√°nh l·∫°i STT sau khi ghi", value=True)
    dry_run = st.checkbox("üß™ Ch·∫°y th·ª≠ (kh√¥ng ghi)", value=True)

    # ƒê·ªÉ gom QR sau upload
    qr_images = []  # danh s√°ch (filename, bytes)

    if file is not None:
        try:
            df_up = pd.read_csv(file) if file.name.lower().endswith(".csv") else pd.read_excel(file)
            df_up = ensure_columns(df_up)
            st.success(f"‚úÖ ƒê√£ ƒë·ªçc {len(df_up)} d√≤ng t·ª´ file.")
            st.dataframe(df_up.head(20), use_container_width=True)

            df_cur = load_df()
            counters = build_unit_counters(df_cur)

            def fill_missing_codes(_df: pd.DataFrame) -> pd.DataFrame:
                _df = _df.copy()
                rows = []
                for _, r in _df.iterrows():
                    r = assign_codes_for_row(r, counters)
                    rows.append(r)
                out = pd.DataFrame(rows, columns=_df.columns)
                if (out["M√£ ƒë∆°n v·ªã"].astype(str).str.len() == 0).any():
                    missing_rows = out[out["M√£ ƒë∆°n v·ªã"].astype(str).str.len() == 0].index.tolist()
                    raise ValueError(f"Kh√¥ng th·ªÉ suy ra 'M√£ ƒë∆°n v·ªã' t·ª´ 'T√™n ƒë∆°n v·ªã' ·ªü c√°c d√≤ng: {', '.join(str(i+2) for i in missing_rows)}")
                return out

            if st.button("üöÄ Th·ª±c thi"):
                if dry_run:
                    st.info("üîé Ch·∫ø ƒë·ªô ch·∫°y th·ª≠: kh√¥ng ghi d·ªØ li·ªáu. B·ªè ch·ªçn ƒë·ªÉ ghi th·∫≠t.")
                else:
                    if mode == "Th√™m (append)":
                        df_to_write = fill_missing_codes(df_up)
                        df_to_write = ensure_codes(df_to_write, df_cur)
                        rows = write_bulk(sheet, df_cur, df_up)   # ghi theo l√¥, t·ª± sinh m√£, ch·ªëng quota
                        st.success(f"‚úÖ ƒê√£ th√™m {rows} d√≤ng.")

                        # t·∫°o QR cho to√†n b·ªô df_to_write
                        for _, r in df_to_write.iterrows():
                            norm = normalize_plate(r["Bi·ªÉn s·ªë"])
                            link = f"https://qrcarump.streamlit.app/?id={urllib.parse.quote(norm)}"
                            png = make_qr_bytes(link)
                            qr_images.append((f"QR_{r['Bi·ªÉn s·ªë']}.png", png))
                        st.success(f"‚úÖ ƒê√£ th√™m {len(values)} d√≤ng.")

                    elif mode == "Thay th·∫ø to√†n b·ªô (replace all)":
                        df_to_write = fill_missing_codes(df_up)
                        gs_retry(sheet.clear, )
                        gs_retry(sheet.update, "A1", [REQUIRED_COLUMNS])
                        df_to_write = ensure_codes(df_to_write, df_cur)
                        values = to_native_ll(df_to_write)
                        if values:
                            gs_retry(sheet.update, f"A2:I{len(values)+1}", values)
                        # t·∫°o QR cho to√†n b·ªô df_to_write
                        for _, r in df_to_write.iterrows():
                            norm = normalize_plate(r["Bi·ªÉn s·ªë"])
                            link = f"https://qrcarump.streamlit.app/?id={urllib.parse.quote(norm)}"
                            png = make_qr_bytes(link)
                            qr_images.append((f"QR_{r['Bi·ªÉn s·ªë']}.png", png))
                        st.success(f"‚úÖ ƒê√£ thay th·∫ø to√†n b·ªô d·ªØ li·ªáu ({len(df_to_write)} d√≤ng).")

                    else:  # upsert
                        df_up2 = fill_missing_codes(df_up)
                        df_cur["__norm"] = df_cur["Bi·ªÉn s·ªë"].astype(str).apply(normalize_plate)
                        df_up2["__norm"] = df_up2["Bi·ªÉn s·ªë"].astype(str).apply(normalize_plate)
                        updated, inserted = 0, 0
                        for _, r in df_up2.iterrows():
                            norm = r["__norm"]
                            match = df_cur[df_cur["__norm"] == norm]
                            payload = [r.get(c, "") for c in REQUIRED_COLUMNS]
                            norm_payload = []
                            for x in payload:
                                if pd.isna(x):
                                    norm_payload.append("")
                                elif isinstance(x, (int, float)):
                                    if isinstance(x, float) and x.is_integer():
                                        norm_payload.append(int(x))
                                    else:
                                        norm_payload.append(float(x) if isinstance(x, float) else int(x))
                                else:
                                    norm_payload.append(str(x))
                            if not match.empty:
                                idx = int(match.index[0])
                                gs_retry(sheet.update, f"A{idx+2}:I{idx+2}", [norm_payload])
                                updated += 1
                            else:
                                gs_retry(sheet.append_row, norm_payload)
                                inserted += 1
                            # QR cho t·ª´ng xe ƒë√£ x·ª≠ l√Ω
                            link = f"https://qrcarump.streamlit.app/?id={urllib.parse.quote(norm)}"
                            png = make_qr_bytes(link)
                            qr_images.append((f"QR_{r['Bi·ªÉn s·ªë']}.png", png))
                        st.success(f"‚úÖ Upsert xong: c·∫≠p nh·∫≠t {updated} ‚Ä¢ th√™m m·ªõi {inserted}.")

                    # ƒê√°nh l·∫°i STT n·∫øu ch·ªçn
                    if not dry_run and auto_stt:
                        try:
                            df_all = load_df()
                            df_all = reindex_stt(df_all)
                            gs_retry(sheet.clear, )
                            gs_retry(sheet.update, "A1", [REQUIRED_COLUMNS])
                            values_all = to_native_ll(df_all)
                            if values_all:
                                gs_retry(sheet.update, f"A2:I{len(values_all)+1}", values_all)
                            st.toast("üî¢ ƒê√£ ƒë√°nh l·∫°i STT 1..N.")
                        except Exception as e:
                            st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ ƒë√°nh l·∫°i STT t·ª± ƒë·ªông: {e}")

                    # N·∫øu c√≥ QR -> g√≥i ZIP ƒë·ªÉ t·∫£i v·ªÅ
                    if not dry_run and qr_images:
                        zip_buf = io.BytesIO()
                        with zipfile.ZipFile(zip_buf, "w", zipfile.ZIP_DEFLATED) as zf:
                            for fname, data in qr_images:
                                zf.writestr(fname, data)
                        zip_buf.seek(0)
                        st.download_button(
                            "üì¶ T·∫£i t·∫•t c·∫£ m√£ QR (.zip)",
                            data=zip_buf.getvalue(),
                            file_name="QR_TatCaXe.zip",
                            mime="application/zip"
                        )
                        st.caption("T·ªáp ZIP ch·ª©a PNG m√£ QR c·ªßa c√°c xe ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω trong l·∫ßn t·∫£i d·ªØ li·ªáu n√†y.")

                    st.toast("üîÑ L√†m m·ªõi d·ªØ li·ªáu hi·ªÉn th·ªã...")
                    st.session_state.df = load_df()

        except Exception as e:
            st.error(f"‚ùå L·ªói khi t·∫£i/ghi d·ªØ li·ªáu: {e}")

elif choice == "üì§ Xu·∫•t ra Excel":
    st.subheader("üì§ T·∫£i danh s√°ch xe d∆∞·ªõi d·∫°ng Excel")
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='DanhSachXe')
    processed_data = output.getvalue()
    st.download_button(
        label="üì• T·∫£i Excel",
        data=processed_data,
        file_name="DanhSachXe.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

elif choice == "üìä Th·ªëng k√™ xe theo ƒë∆°n v·ªã":
    st.markdown("## üìä Dashboard th·ªëng k√™ xe theo ƒë∆°n v·ªã")
    df_stats = df.copy()
    ten_day_du = {
        "HCTH": "Ph√≤ng H√†nh Ch√≠nh T·ªïng h·ª£p",
        "TCCB": "Ph√≤ng T·ªï ch·ª©c C√°n b·ªô",
        "ƒêTƒêH": "Ph√≤ng ƒê√†o t·∫°o ƒê·∫°i h·ªçc",
        "ƒêTSƒêH": "Ph√≤ng ƒê√†o t·∫°o Sau ƒë·∫°i h·ªçc",
        "KHCN": "Ph√≤ng Khoa h·ªçc C√¥ng ngh·ªá",
        "KHTC": "Ph√≤ng K·∫ø ho·∫°ch T√†i ch√≠nh",
        "QTGT": "Ph√≤ng Qu·∫£n tr·ªã Gi√°o t√†i",
        "TTPC": "Ph√≤ng Thanh tra Ph√°p ch·∫ø",
        "ƒêBCLGD&KT": "Ph√≤ng ƒê·∫£m b·∫£o ch·∫•t l∆∞·ª£ng GD v√† Kh·∫£o th√≠",
        "CTSV": "Ph√≤ng C√¥ng t√°c sinh vi√™n",
        "HTQT": "Ph√≤ng H·ª£p t√°c Qu·ªëc t·∫ø",
        "KHCB": "Khoa Khoa h·ªçc C∆° b·∫£n",
        "RHM": "Khoa RƒÉng h√†m m·∫∑t",
        "YTCC": "Khoa Y t·∫ø C√¥ng c·ªông",
        "YHCT": "Khoa Y h·ªçc C·ªï truy·ªÅn",
        "PK.CKRHM": "Ph√≤ng kh√°m RHM",
        "TT.KCCLXN": "Trung t√¢m Ki·ªÉm chu·∫©n CLXN",
        "TT.KHCN UMP": "Trung t√¢m KHCN UMP",
        "TT.YSHPT": "Trung t√¢m Y sinh h·ªçc ph√¢n t·ª≠",
        "KTX": "K√Ω t√∫c x√°",
        "BV ƒêHYD": "B·ªánh vi·ªán ƒêHYD",
        "TT.PTTN": "Trung t√¢m PTTN",
        "TT. GDYH": "Trung t√¢m GDYH",
        "VPƒê": "VP ƒêo√†n th·ªÉ",
        "Tr∆∞·ªùng Y": "Tr∆∞·ªùng Y",
        "Tr∆∞·ªùng D∆∞·ª£c": "Tr∆∞·ªùng D∆∞·ª£c",
        "Tr∆∞·ªùng ƒêD-KTYH": "Tr∆∞·ªùng ƒêD-KTYH",
        "Th∆∞ vi·ªán": "Th∆∞ vi·ªán",
        "T·∫°p ch√≠ Y h·ªçc": "T·∫°p ch√≠ Y h·ªçc"
    }
    thong_ke = df_stats.groupby("T√™n ƒë∆°n v·ªã").size().reset_index(name="S·ªë l∆∞·ª£ng xe")
    thong_ke = thong_ke.sort_values(by="S·ªë l∆∞·ª£ng xe", ascending=False)
    thong_ke["T√™n ƒë·∫ßy ƒë·ªß"] = thong_ke["T√™n ƒë∆°n v·ªã"].apply(lambda x: ten_day_du.get(x, x))
    import plotly.express as px
    fig = px.bar(thong_ke, x="T√™n ƒë∆°n v·ªã", y="S·ªë l∆∞·ª£ng xe", color="T√™n ƒë∆°n v·ªã", text="S·ªë l∆∞·ª£ng xe",
                 title="üìà Bi·ªÉu ƒë·ªì s·ªë l∆∞·ª£ng xe theo ƒë∆°n v·ªã")
    fig.update_traces(textposition="outside")
    fig.update_layout(showlegend=False, height=600)
    col = st.columns([0.1, 0.9])
    with col[1]:
        st.plotly_chart(fig, use_container_width=True)
    st.markdown("#### üìã B·∫£ng th·ªëng k√™ chi ti·∫øt")
    thong_ke_display = thong_ke[["T√™n ƒë·∫ßy ƒë·ªß", "S·ªë l∆∞·ª£ng xe"]].rename(columns={"T√™n ƒë·∫ßy ƒë·ªß": "T√™n ƒë∆°n v·ªã"})
    thong_ke_display.index = range(1, len(thong_ke_display) + 1)
    st.dataframe(thong_ke_display, use_container_width=True)
# ====================== üéÅ T·∫†O M√É QR H√ÄNG LO·∫†T ======================
elif choice == "üéÅ T·∫°o m√£ QR h√†ng lo·∫°t":
    st.subheader("üéÅ T·∫°o m√£ QR h√†ng lo·∫°t")

    # URL GitHub Pages (n∆°i nh√∫ng app Streamlit)
    BASE_URL_QR = "https://dhnamgh.github.io/car/"

    # Ch·ªçn ngu·ªìn d·ªØ li·ªáu
    src_opt = st.radio("Ch·ªçn ngu·ªìn d·ªØ li·ªáu", ["To√†n b·ªô danh s√°ch", "Danh s√°ch ƒëang l·ªçc"], horizontal=True)

    # L·∫•y d·ªØ li·ªáu g·ªëc ho·∫∑c danh s√°ch ƒëang hi·ªÉn th·ªã
    if src_opt == "Danh s√°ch ƒëang l·ªçc" and "df_show" in locals():
        df_qr = df_show.copy()
    else:
        df_qr = df.copy()

    # Chu·∫©n ho√° c·ªôt ƒë·ªÉ ch·∫Øc ch·∫Øn c√≥ c√°c c·ªôt c·∫ßn thi·∫øt
    df_qr = coerce_columns(df_qr)
    for col in ["M√£ th·∫ª", "Bi·ªÉn s·ªë", "M√£ ƒë∆°n v·ªã"]:
        if col not in df_qr.columns:
            df_qr[col] = ""

    st.info(f"M·ªói m√£ QR s·∫Ω m·ªü trang: {BASE_URL_QR}?id=<M√£Th·∫ª>")

    if st.button("‚ö° T·∫°o ZIP m√£ QR"):
        import io, zipfile, urllib.parse

        if df_qr.empty:
            st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ t·∫°o QR.")
        else:
            files = []
            for _, r in df_qr.iterrows():
                # ∆Øu ti√™n M√£ th·∫ª, fallback Bi·ªÉn s·ªë (ƒë√£ chu·∫©n ho√°)
                vid = str(r.get("M√£ th·∫ª", "")).strip()
                if not vid and "Bi·ªÉn s·ªë" in df_qr.columns:
                    vid = normalize_plate(r.get("Bi·ªÉn s·ªë", ""))
                if not vid:
                    continue

                url = f"{BASE_URL_QR}?id={urllib.parse.quote(vid)}"  # KH√îNG th√™m m·∫≠t kh·∫©u
                png = make_qr_bytes(url)

                unit = str(r.get("M√£ ƒë∆°n v·ªã", "")).strip().upper() or "NO_UNIT"
                files.append((f"{unit}/{vid}.png", png))

            if not files:
                st.warning("Kh√¥ng c√≥ b·∫£n ghi h·ª£p l·ªá ƒë·ªÉ t·∫°o QR.")
            else:
                buf = io.BytesIO()
                with zipfile.ZipFile(buf, "w", zipfile.ZIP_STORED) as zf:
                    for name, data in files:
                        zf.writestr(name, data)
                buf.seek(0)

                st.download_button(
                    "‚¨áÔ∏è T·∫£i ZIP QR (ph√¢n theo ƒë∆°n v·ªã)",
                    data=buf.getvalue(),
                    file_name="qr_xe_theo_don_vi.zip",
                    mime="application/zip"
                )
                st.success(f"‚úÖ ƒê√£ t·∫°o {len(files)} QR v√† g√≥i ZIP s·∫µn s√†ng t·∫£i v·ªÅ.")
                st.caption("Qu√©t QR s·∫Ω m·ªü GitHub Pages, app s·∫Ω y√™u c·∫ßu m·∫≠t kh·∫©u QR (t·ª´ st.secrets).")
# ====================== /üéÅ T·∫†O M√É QR H√ÄNG LO·∫†T ======================

elif choice == "ü§ñ Tr·ª£ l√Ω AI":
    st.subheader("ü§ñ Tr·ª£ l√Ω AI (AI nh·∫π, kh√¥ng d√πng API)")
    q = st.text_input("G√µ c√¢u t·ª± nhi√™n: v√≠ d·ª• 'xe c·ªßa Tr∆∞·ªùng Y t√™n H√πng', '59A1', 'email @ump.edu.vn', '0912345678'‚Ä¶")
    if q:
        keys = simple_query_parser(q)
        with st.expander("Xem c√°ch app hi·ªÉu c√¢u h·ªèi (keys)", expanded=False):
            st.json(keys)
        filtered, applied = filter_with_keys(df, keys)
        if applied and not filtered.empty:
            st.success(f"‚úÖ L·ªçc theo √Ω hi·ªÉu ƒë∆∞·ª£c {len(filtered)} d√≤ng. S·∫Øp x·∫øp g·ª£i √Ω th√¥ng minh‚Ä¶")
            ranked = fuzzy_search_df(filtered, q, topk=50)
            st.dataframe(ranked.drop(columns=["__score__"], errors="ignore"), use_container_width=True)
        else:
            st.info("Kh√¥ng l·ªçc ƒë∆∞·ª£c r√µ r√†ng t·ª´ c√¢u h·ªèi. Th·ª≠ g·ª£i √Ω g·∫ßn ƒë√∫ng to√†n b·ªô‚Ä¶")
            top = fuzzy_search_df(df, q, topk=50)
            if top.empty:
                st.warning("üö´ Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£.")
            else:
                st.dataframe(top.drop(columns=["__score__"], errors="ignore"), use_container_width=True)

# ---------- Footer ----------
st.markdown("""
<hr style='margin-top:50px; margin-bottom:20px;'>

<div style='font-size:14px; line-height:1.6; text-align:center; color:#444;'>
    <strong>Ph√≤ng H√†nh ch√≠nh T·ªïng H·ª£p - ƒê·∫°i h·ªçc Y D∆∞·ª£c Th√†nh ph·ªë H·ªì Ch√≠ Minh</strong><br>
    ƒê·ªãa ch·ªâ: 217 H·ªìng B√†ng, Ph∆∞·ªùng Ch·ª£ L·ªõn, TP. H·ªì Ch√≠ Minh<br>
    ƒêT: (+84-28) 3855 8411 - (+84-28) 3853 7949 - (+84-28) 3855 5780<br>
    Fax: (+84-28) 3855 2304<br>
    Email: <a href='mailto:hanhchinh@ump.edu.vn'>hanhchinh@ump.edu.vn</a><br><br>
    <em>Copyright ¬© 2025 B·∫£n quy·ªÅn thu·ªôc v·ªÅ Ph√≤ng H√†nh ch√≠nh T·ªïng H·ª£p - ƒê·∫°i h·ªçc Y D∆∞·ª£c Th√†nh ph·ªë H·ªì Ch√≠ Minh</em>
</div>
""", unsafe_allow_html=True)
